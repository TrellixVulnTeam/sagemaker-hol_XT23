{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfd98b5",
   "metadata": {},
   "source": [
    "# Fashion-MNIST PyTorch image classification w/ Tensorboard\n",
    "Source\n",
    "- https://tutorials.pytorch.kr/intermediate/tensorboard_tutorial.html\n",
    "- https://github.com/aws/amazon-sagemaker-examples/blob/master/frameworks/pytorch/get_started_mnist_train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5483be",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328120fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f188b212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (2.72.0)\n",
      "Collecting sagemaker[local]\n",
      "  Downloading sagemaker-2.72.1.tar.gz (473 kB)\n",
      "     |████████████████████████████████| 473 kB 1.9 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (21.2.0)\n",
      "Requirement already satisfied: boto3>=1.20.18 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (1.20.24)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (1.21.4)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (21.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (1.3.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25,!=1.25.1,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (1.26.7)\n",
      "Requirement already satisfied: docker-compose>=1.25.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: docker==5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker[local]) (5.0.0)\n",
      "Collecting PyYAML<6,>=5.3\n",
      "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker==5.0.0->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker==5.0.0->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker[local]) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker[local]) (1.23.24)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker[local]) (0.10.0)\n",
      "Collecting jsonschema<4,>=2.5.1\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: cached-property<2,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.2)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.0)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.6.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from packaging>=20.0->sagemaker[local]) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->sagemaker[local]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->sagemaker[local]) (2021.3)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker==5.0.0->sagemaker[local]) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (58.5.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (0.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2.0.7)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (35.0.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (2.21)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.72.1-py2.py3-none-any.whl size=650653 sha256=4b32cd38aef73debbd81b1aa311f360c09dd733c402663d379088c3c86480899\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/2d/2f/42/cb1762fdbe69d2b678e36c3b81e9f6fa2c03b08d5de5471edd\n",
      "Successfully built sagemaker\n",
      "\u001b[33mWARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: PyYAML, jsonschema, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "\u001b[31mERROR: Cannot uninstall PyYAML 6.0, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps PyYAML==6.0'.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker-experiments in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.1.35)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker-experiments) (1.20.24)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.23.24)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.24->boto3>=1.16.27->sagemaker-experiments) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.24->boto3>=1.16.27->sagemaker-experiments) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3>=1.16.27->sagemaker-experiments) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA'\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (2.72.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.72.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.21.4)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: boto3>=1.20.18 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.20.24)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (21.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (4.8.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.3.4)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker) (1.23.24)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.24->boto3>=1.20.18->sagemaker) (1.26.7)\n",
      "\u001b[33mWARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.72.0\n",
      "    Uninstalling sagemaker-2.72.0:\n",
      "      Successfully uninstalled sagemaker-2.72.0\n",
      "Successfully installed sagemaker-2.72.1\n",
      "/bin/bash: ./local/local_mode_setup.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U 'sagemaker[local]'\n",
    "    !{sys.executable} -m pip install -U sagemaker-experiments # SageMaker Experiments SDK \n",
    "    !{sys.executable} -m pip install -U sagemaker             # SageMaker Python SDK\n",
    "    !/bin/bash ./local/local_mode_setup.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca36ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344af2e",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c820f98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c24308e750944cd86531dff3089b92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be49cf1ea3db4f899a625570084c4e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8736b28a6243ce95a8e321effb2871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ea887bd4284451bc51eb5e76d5f3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711554f7",
   "metadata": {},
   "source": [
    "## Set up the SageMaker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400eb4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-ap-northeast-2-889750940888\n",
      "SageMaker ver: 2.68.0\n",
      "Tensorboard log path: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from smexperiments.experiment import Experiment ### SM Experiment\n",
    "from smexperiments.trial import Trial           ### SM Experiment\n",
    "\n",
    "from sagemaker.debugger import TensorBoardOutputConfig ### For TensorBoard \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"tensorboard_pytorch_fashion_mnist\"\n",
    "tensorboard_logs_path = \"s3://{}/{}/logs\".format(bucket, prefix) ### For TensorBoard\n",
    "output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "print(\"Bucket: {}\".format(bucket))\n",
    "print(\"SageMaker ver: \" + sagemaker.__version__)\n",
    "print(\"Tensorboard log path: {}\".format(tensorboard_logs_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387689f5",
   "metadata": {},
   "source": [
    "## Uploading the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67999a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/t10k-labels-idx1-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte\n",
      "upload: data/FashionMNIST/raw/train-labels-idx1-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte\n",
      "upload: data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/t10k-images-idx3-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte\n",
      "upload: data/FashionMNIST/raw/train-images-idx3-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/train-images-idx3-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./data/FashionMNIST/raw s3://{bucket}/{prefix}/data --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14afce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = 's3://{}/{}/data'.format(bucket, prefix)\n",
    "test_location = 's3://{}/{}/data'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b146ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22 00:12:46    7840016 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte\n",
      "2021-12-22 00:12:46    4422102 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte.gz\n",
      "2021-12-22 00:12:46      10008 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte\n",
      "2021-12-22 00:12:46       5148 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "2021-12-22 00:12:46   47040016 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte\n",
      "2021-12-22 00:12:46   26421880 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte.gz\n",
      "2021-12-22 00:12:46      60008 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte\n",
      "2021-12-22 00:12:46      29515 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {train_location} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cc7864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22 00:12:46    7840016 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte\n",
      "2021-12-22 00:12:46    4422102 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte.gz\n",
      "2021-12-22 00:12:46      10008 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte\n",
      "2021-12-22 00:12:46       5148 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "2021-12-22 00:12:46   47040016 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte\n",
      "2021-12-22 00:12:46   26421880 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte.gz\n",
      "2021-12-22 00:12:46      60008 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte\n",
      "2021-12-22 00:12:46      29515 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {test_location} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af365b49",
   "metadata": {},
   "source": [
    "## Local mode training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399a8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.local import LocalSession\n",
    "# sagemaker_session = LocalSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c405107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import TensorBoardOutputConfig ### For TensorBoard \n",
    "\n",
    "# An error occurred (ValidationException) when calling the CreateTrainingJob operation:\n",
    "# \"LocalPath\" of \"TensorBoardOutputConfig\" cannot start with the following reserved path: [/opt/ml, /tmp, /usr/local/nvidia]\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_logs_path,\n",
    "    container_local_output_path='/pytorch/tensors' # See code/train.py\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b84f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_local = {\"batch-size\": 128,\n",
    "                         \"epochs\": 1,\n",
    "                         \"learning-rate\": 1e-3,\n",
    "                         \"log-interval\": 100,\n",
    "                         \"tensorboard-logs-path\": tensorboard_logs_path} # Not working in local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7257cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local_mode to be True if you want to run the training script\n",
    "# on the machine that runs this notebook\n",
    "\n",
    "local_mode = True\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "est_local = PyTorch(\n",
    "            entry_point=\"train.py\",\n",
    "            source_dir=\"code\",  # directory of your training script\n",
    "            role=role,\n",
    "            framework_version=\"1.8.1\",\n",
    "            py_version=\"py3\",\n",
    "            instance_type=instance_type,\n",
    "            instance_count=1,\n",
    "            output_path=output_path,\n",
    "            hyperparameters=hyperparameters_local,\n",
    "            tensorboard_output_config=tensorboard_output_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa61809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2021-12-22-00-13-14-352\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-jxhg8:\n",
      "    command: train\n",
      "    container_name: tuagljbb8u-algo-1-jxhg8\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-training:1.8.1-cpu-py3\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-jxhg8\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp77n_ozch/algo-1-jxhg8/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmp77n_ozch/algo-1-jxhg8/output:/opt/ml/output\n",
      "    - /tmp/tmp77n_ozch/algo-1-jxhg8/input:/opt/ml/input\n",
      "    - /tmp/tmp77n_ozch/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /tmp/tmp6454u2cz:/opt/ml/input/data/training\n",
      "    - /tmp/tmp95d5t1_e:/opt/ml/input/data/testing\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmp77n_ozch/docker-compose.yaml up --build --abort-on-container-exit\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker pull 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-training:1.8.1-cpu-py3\n",
      "INFO:sagemaker.local.image:image pulled: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-training:1.8.1-cpu-py3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tuagljbb8u-algo-1-jxhg8 ... \n",
      "Creating tuagljbb8u-algo-1-jxhg8 ... done\n",
      "Attaching to tuagljbb8u-algo-1-jxhg8\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:22,018 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:22,020 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:22,029 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:22,031 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:22,162 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting tensorboard<2.4\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "     |████████████████████████████████| 6.8 MB 1.8 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.26.0)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting markdown>=2.6.8\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 14.3 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.16.0)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting absl-py>=0.4\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "     |████████████████████████████████| 126 kB 81.6 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting tensorboard-plugin-wit>=1.6.0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 44.1 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (3.19.1)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.19.1)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting grpcio>=1.24.3\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading grpcio-1.43.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "     |████████████████████████████████| 4.1 MB 58.6 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (58.0.4)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.0.2)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting google-auth<2,>=1.6.3\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 74.2 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (0.36.2)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (4.7.2)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting cachetools<5.0,>=2.0.0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 78.7 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (4.8.3)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.0.4)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.10)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (1.26.6)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2021.5.30)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.4->-r requirements.txt (line 1)) (0.8)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.6.0)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (0.4.8)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Collecting oauthlib>=3.0.0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m   Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "     |████████████████████████████████| 146 kB 88.5 MB/s            \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \u001b[?25hInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Successfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.43.0 markdown-3.3.6 oauthlib-3.1.1 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.3.0 tensorboard-plugin-wit-1.8.0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:27,359 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:27,372 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:27,382 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:27,390 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Training Env:\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"testing\": \"/opt/ml/input/data/testing\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     },\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"current_host\": \"algo-1-jxhg8\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"algo-1-jxhg8\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     ],\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"batch-size\": 128,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"learning-rate\": 0.001,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"log-interval\": 100,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"tensorboard-logs-path\": \"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     },\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"training\": {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         },\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"testing\": {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         }\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     },\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"job_name\": \"pytorch-training-2021-12-22-00-13-14-352\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"master_hostname\": \"algo-1-jxhg8\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/pytorch-training-2021-12-22-00-13-14-352/source/sourcedir.tar.gz\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"current_host\": \"algo-1-jxhg8\",\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m             \"algo-1-jxhg8\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m         ]\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     },\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m }\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Environment variables:\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HOSTS=[\"algo-1-jxhg8\"]\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HPS={\"batch-size\":128,\"epochs\":1,\"learning-rate\":0.001,\"log-interval\":100,\"tensorboard-logs-path\":\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"}\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-jxhg8\",\"hosts\":[\"algo-1-jxhg8\"]}\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_INPUT_DATA_CONFIG={\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_CHANNELS=[\"testing\",\"training\"]\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_CURRENT_HOST=algo-1-jxhg8\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/pytorch-training-2021-12-22-00-13-14-352/source/sourcedir.tar.gz\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-jxhg8\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-jxhg8\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":1,\"learning-rate\":0.001,\"log-interval\":100,\"tensorboard-logs-path\":\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-12-22-00-13-14-352\",\"log_level\":20,\"master_hostname\":\"algo-1-jxhg8\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/pytorch-training-2021-12-22-00-13-14-352/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-jxhg8\",\"hosts\":[\"algo-1-jxhg8\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"1\",\"--learning-rate\",\"0.001\",\"--log-interval\",\"100\",\"--tensorboard-logs-path\",\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"]\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_CHANNEL_TESTING=/opt/ml/input/data/testing\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HP_BATCH-SIZE=128\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HP_LEARNING-RATE=0.001\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HP_LOG-INTERVAL=100\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m SM_HP_TENSORBOARD-LOGS-PATH=s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m /opt/conda/bin/python3.6 train.py --batch-size 128 --epochs 1 --learning-rate 0.001 --log-interval 100 --tensorboard-logs-path s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m [2021-12-22 00:14:29.484 algo-1-jxhg8:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m [2021-12-22 00:14:29.642 algo-1-jxhg8:33 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Start training ...\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Train Epoch: 1 [12800/60000 (21%)] Loss: 0.978605\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Train Epoch: 1 [25600/60000 (43%)] Loss: 0.786802\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Train Epoch: 1 [38400/60000 (64%)] Loss: 0.658286\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Train Epoch: 1 [51200/60000 (85%)] Loss: 0.703871\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Test set: Average loss: 0.5355, Accuracy: 7966/10000, 79.66)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m Saving the model\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m INFO:__main__:Start training ...\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m INFO:__main__:Test set: Average loss: 0.5355, Accuracy: 7966/10000, 79.66)\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m INFO:__main__:Saving the model\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m \n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 |\u001b[0m 2021-12-22 00:14:35,603 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mtuagljbb8u-algo-1-jxhg8 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "channels = {\"training\": train_location, \"testing\": test_location}\n",
    "est_local.fit(inputs=channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392126ee",
   "metadata": {},
   "source": [
    "## Managed training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b174e",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a80999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[\n",
    "                                              {\n",
    "                                                  'Key': 'modelname',\n",
    "                                                  'Value': 'fashion-mnist'\n",
    "                                              },\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4702194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, i_type, i_cnt, spot):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    \n",
    "    algo = 'dp'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_tag = 'test'\n",
    "    \n",
    "    if i_type == 'ml.p3.16xlarge':\n",
    "        i_tag = 'p3'\n",
    "    elif i_type == 'ml.p2.8xlarge':\n",
    "        i_tag = 'p2'\n",
    "    elif i_type == 'ml.p3dn.24xlarge':\n",
    "        i_tag = 'p3dn'\n",
    "    elif i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'\n",
    "    else:\n",
    "        i_tag = 'others'\n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431323c",
   "metadata": {},
   "source": [
    "### Debugger rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86e5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929d6d0",
   "metadata": {},
   "source": [
    "### Debugger Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de909824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5718d003",
   "metadata": {},
   "source": [
    "### Training environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93894301",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{'Name': 'average loss',\n",
    "                       'Regex': 'Average loss: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'accuracy',\n",
    "                       'Regex': 'Accuracy: [0-9]+/[0-9]+, ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c50f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metric_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4b4ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"batch-size\": 128,\n",
    "                   \"epochs\": 100,\n",
    "                   \"learning-rate\": 1e-3,\n",
    "                   \"log-interval\": 100,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02c79d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local_mode to be True if you want to run the training script\n",
    "# on the machine that runs this notebook\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "instance_count = 1\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "            entry_point=\"train.py\",\n",
    "            source_dir=\"code\",  # directory of your training script\n",
    "            role=role,\n",
    "            framework_version=\"1.8.1\",\n",
    "            py_version=\"py3\",\n",
    "            instance_type=instance_type,\n",
    "            instance_count=instance_count,\n",
    "            output_path=output_path,\n",
    "            hyperparameters=hyperparameters,\n",
    "            tensorboard_output_config=tensorboard_output_config,\n",
    "            base_job_name='pytorch-tensorboard',\n",
    "            metric_definitions=metric_definitions,\n",
    "            profiler_config=profiler_config,\n",
    "            rules=rules,\n",
    "            disable_profiler=False # default: False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60279ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-tensorboard-others-1-dp-d-1222-00401640133602'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'pytorch-tensorboard'\n",
    "do_spot_training=False\n",
    "\n",
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, instance_type, instance_count, do_spot_training)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08201341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-tensorboard-2021-12-22-00-40-07-255\n"
     ]
    }
   ],
   "source": [
    "channels = {\"training\": train_location, \"testing\": test_location}\n",
    "estimator.fit(inputs=channels,\n",
    "              experiment_config={\n",
    "                  'TrialName': job_name,\n",
    "                  'TrialComponentDisplayName': job_name,\n",
    "                },\n",
    "              wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfb8e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22 00:40:10 Starting - Starting the training job...\n",
      "2021-12-22 00:40:33 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2021-12-22 00:41:33 Starting - Preparing the instances for training......\n",
      "2021-12-22 00:42:40 Downloading - Downloading input data...\n",
      "2021-12-22 00:43:10 Training - Downloading the training image.........................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-12-22 00:47:12,817 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-12-22 00:47:12,842 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-12-22 00:47:12,862 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-12-22 00:47:13,494 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting tensorboard<2.4\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (58.0.4)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (0.36.2)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (3.19.1)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (4.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.4->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.43.0 markdown-3.3.6 oauthlib-3.1.1 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.3.0 tensorboard-plugin-wit-1.8.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2021-12-22 00:47:22,013 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"log-interval\": 100,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"epochs\": 100\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-tensorboard-2021-12-22-00-40-07-255\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/pytorch-tensorboard-2021-12-22-00-40-07-255/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":100,\"learning-rate\":0.001,\"log-interval\":100}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/pytorch-tensorboard-2021-12-22-00-40-07-255/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":100,\"learning-rate\":0.001,\"log-interval\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-tensorboard-2021-12-22-00-40-07-255\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/pytorch-tensorboard-2021-12-22-00-40-07-255/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"100\",\"--learning-rate\",\"0.001\",\"--log-interval\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch-size 128 --epochs 100 --learning-rate 0.001 --log-interval 100\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:28.424 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:28.545 algo-1:33 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:28.547 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:28.550 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:28.550 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mStart training ...\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.171 algo-1:33 INFO hook.py:591] name:conv1.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.171 algo-1:33 INFO hook.py:591] name:conv1.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.172 algo-1:33 INFO hook.py:591] name:conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.172 algo-1:33 INFO hook.py:591] name:conv2.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.172 algo-1:33 INFO hook.py:591] name:fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.173 algo-1:33 INFO hook.py:591] name:fc1.bias count_params:50\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.173 algo-1:33 INFO hook.py:591] name:fc2.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.174 algo-1:33 INFO hook.py:591] name:fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.174 algo-1:33 INFO hook.py:593] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.174 algo-1:33 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.176 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/prestepzero-*-start-1640134048546124.8_global-0-stepstart-1640134055176042.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:35.193 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:46.503 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-0-stepstart-1640134055188084.2_global-0-forwardpassend-1640134066502630.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:47.355 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-0-forwardpassend-1640134066505778.5_global-1-stepstart-1640134067354170.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:48.048 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-1-stepstart-1640134067359629.0_global-1-forwardpassend-1640134068048207.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:48.078 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-1-forwardpassend-1640134068052306.5_global-2-stepstart-1640134068077539.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:48.625 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-2-stepstart-1640134068080480.2_global-2-forwardpassend-1640134068624349.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:48.651 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-2-forwardpassend-1640134068626730.0_global-3-stepstart-1640134068650936.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:49.207 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-3-stepstart-1640134068653849.0_global-3-forwardpassend-1640134069206257.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:49.234 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-3-forwardpassend-1640134069208576.5_global-4-stepstart-1640134069233873.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:49.875 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-4-stepstart-1640134069236738.0_global-4-forwardpassend-1640134069874717.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:49.905 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-4-forwardpassend-1640134069878315.5_global-5-stepstart-1640134069904096.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:50.552 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-5-stepstart-1640134069907492.5_global-5-forwardpassend-1640134070551128.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:50.585 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-5-forwardpassend-1640134070554399.5_global-6-stepstart-1640134070584664.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:51.139 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-6-stepstart-1640134070588106.2_global-6-forwardpassend-1640134071138622.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:51.167 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-6-forwardpassend-1640134071141535.2_global-7-stepstart-1640134071166079.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:51.726 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-7-stepstart-1640134071168951.0_global-7-forwardpassend-1640134071725288.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:51.753 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-7-forwardpassend-1640134071727827.5_global-8-stepstart-1640134071753356.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:52.364 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-8-stepstart-1640134071756119.5_global-8-forwardpassend-1640134072363323.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:52.390 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-8-forwardpassend-1640134072366063.2_global-9-stepstart-1640134072389938.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:52.973 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-9-stepstart-1640134072392928.5_global-9-forwardpassend-1640134072972212.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 00:47:53.001 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-9-forwardpassend-1640134072975000.5_global-10-stepstart-1640134073000274.2/python_stats.\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)] Loss: 1.040341\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)] Loss: 0.745914\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)] Loss: 0.683272\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)] Loss: 0.772972\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5407, Accuracy: 7972/10000, 79.72)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)] Loss: 0.557672\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)] Loss: 0.732685\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)] Loss: 0.749402\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)] Loss: 0.742642\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4667, Accuracy: 8311/10000, 83.11)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12800/60000 (21%)] Loss: 0.582953\u001b[0m\n",
      "\n",
      "2021-12-22 00:48:12 Training - Training image download completed. Training in progress.\u001b[34mTrain Epoch: 3 [25600/60000 (43%)] Loss: 0.407319\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [38400/60000 (64%)] Loss: 0.503883\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [51200/60000 (85%)] Loss: 0.569439\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4316, Accuracy: 8426/10000, 84.26)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12800/60000 (21%)] Loss: 0.467580\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [25600/60000 (43%)] Loss: 0.570148\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [38400/60000 (64%)] Loss: 0.460298\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [51200/60000 (85%)] Loss: 0.397055\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4136, Accuracy: 8512/10000, 85.12)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [12800/60000 (21%)] Loss: 0.500148\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [25600/60000 (43%)] Loss: 0.471674\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [38400/60000 (64%)] Loss: 0.567669\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [51200/60000 (85%)] Loss: 0.545978\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3897, Accuracy: 8568/10000, 85.68)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [12800/60000 (21%)] Loss: 0.538784\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [25600/60000 (43%)] Loss: 0.464723\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [38400/60000 (64%)] Loss: 0.506139\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [51200/60000 (85%)] Loss: 0.446334\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3797, Accuracy: 8603/10000, 86.03)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [12800/60000 (21%)] Loss: 0.470107\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [25600/60000 (43%)] Loss: 0.481841\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [38400/60000 (64%)] Loss: 0.540288\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [51200/60000 (85%)] Loss: 0.428033\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3697, Accuracy: 8605/10000, 86.05)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [12800/60000 (21%)] Loss: 0.472189\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [25600/60000 (43%)] Loss: 0.395927\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [38400/60000 (64%)] Loss: 0.380039\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [51200/60000 (85%)] Loss: 0.455282\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3619, Accuracy: 8686/10000, 86.86)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [12800/60000 (21%)] Loss: 0.429492\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [25600/60000 (43%)] Loss: 0.471828\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [38400/60000 (64%)] Loss: 0.671249\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [51200/60000 (85%)] Loss: 0.381949\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3543, Accuracy: 8690/10000, 86.9)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [12800/60000 (21%)] Loss: 0.481777\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [25600/60000 (43%)] Loss: 0.530583\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [38400/60000 (64%)] Loss: 0.495817\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [51200/60000 (85%)] Loss: 0.399638\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3465, Accuracy: 8712/10000, 87.12)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [12800/60000 (21%)] Loss: 0.381485\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [25600/60000 (43%)] Loss: 0.389394\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [38400/60000 (64%)] Loss: 0.389476\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [51200/60000 (85%)] Loss: 0.451653\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3388, Accuracy: 8745/10000, 87.45)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [12800/60000 (21%)] Loss: 0.429052\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [25600/60000 (43%)] Loss: 0.412904\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [38400/60000 (64%)] Loss: 0.355703\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [51200/60000 (85%)] Loss: 0.439855\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3380, Accuracy: 8744/10000, 87.44)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [12800/60000 (21%)] Loss: 0.319097\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [25600/60000 (43%)] Loss: 0.538268\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [38400/60000 (64%)] Loss: 0.517415\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [51200/60000 (85%)] Loss: 0.331245\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3391, Accuracy: 8776/10000, 87.76)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [12800/60000 (21%)] Loss: 0.444099\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [25600/60000 (43%)] Loss: 0.434754\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [38400/60000 (64%)] Loss: 0.533209\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [51200/60000 (85%)] Loss: 0.404134\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3291, Accuracy: 8807/10000, 88.07)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [12800/60000 (21%)] Loss: 0.356838\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [25600/60000 (43%)] Loss: 0.497404\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [38400/60000 (64%)] Loss: 0.333457\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [51200/60000 (85%)] Loss: 0.436748\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3314, Accuracy: 8790/10000, 87.9)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [12800/60000 (21%)] Loss: 0.565255\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [25600/60000 (43%)] Loss: 0.352913\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [38400/60000 (64%)] Loss: 0.316565\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [51200/60000 (85%)] Loss: 0.354853\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3309, Accuracy: 8805/10000, 88.05)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [12800/60000 (21%)] Loss: 0.401212\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [25600/60000 (43%)] Loss: 0.436089\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [38400/60000 (64%)] Loss: 0.288960\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [51200/60000 (85%)] Loss: 0.403151\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3187, Accuracy: 8820/10000, 88.2)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [12800/60000 (21%)] Loss: 0.443363\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [25600/60000 (43%)] Loss: 0.305493\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [38400/60000 (64%)] Loss: 0.472653\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [51200/60000 (85%)] Loss: 0.411886\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3200, Accuracy: 8829/10000, 88.29)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [12800/60000 (21%)] Loss: 0.346164\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [25600/60000 (43%)] Loss: 0.448625\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [38400/60000 (64%)] Loss: 0.384201\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [51200/60000 (85%)] Loss: 0.377214\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3244, Accuracy: 8835/10000, 88.35)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [12800/60000 (21%)] Loss: 0.444727\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [25600/60000 (43%)] Loss: 0.344106\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [38400/60000 (64%)] Loss: 0.413766\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [51200/60000 (85%)] Loss: 0.465968\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3190, Accuracy: 8819/10000, 88.19)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [12800/60000 (21%)] Loss: 0.412489\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [25600/60000 (43%)] Loss: 0.262835\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [38400/60000 (64%)] Loss: 0.384261\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [51200/60000 (85%)] Loss: 0.354957\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3187, Accuracy: 8834/10000, 88.34)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [12800/60000 (21%)] Loss: 0.425289\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [25600/60000 (43%)] Loss: 0.363526\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [38400/60000 (64%)] Loss: 0.345335\u001b[0m\n",
      "LossNotDecreasing: IssuesFound\n",
      "\u001b[34mTrain Epoch: 22 [51200/60000 (85%)] Loss: 0.353309\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3136, Accuracy: 8830/10000, 88.3)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [12800/60000 (21%)] Loss: 0.338658\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [25600/60000 (43%)] Loss: 0.285227\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [38400/60000 (64%)] Loss: 0.471349\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [51200/60000 (85%)] Loss: 0.306639\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3141, Accuracy: 8842/10000, 88.42)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [12800/60000 (21%)] Loss: 0.362761\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [25600/60000 (43%)] Loss: 0.431724\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [38400/60000 (64%)] Loss: 0.409937\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [51200/60000 (85%)] Loss: 0.446385\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3178, Accuracy: 8826/10000, 88.26)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [12800/60000 (21%)] Loss: 0.382258\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [25600/60000 (43%)] Loss: 0.368333\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [38400/60000 (64%)] Loss: 0.354711\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [51200/60000 (85%)] Loss: 0.349039\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3143, Accuracy: 8855/10000, 88.55)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [12800/60000 (21%)] Loss: 0.441673\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [25600/60000 (43%)] Loss: 0.560890\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [38400/60000 (64%)] Loss: 0.425732\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [51200/60000 (85%)] Loss: 0.435558\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3081, Accuracy: 8885/10000, 88.85)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [12800/60000 (21%)] Loss: 0.347569\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [25600/60000 (43%)] Loss: 0.320896\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [38400/60000 (64%)] Loss: 0.378820\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [51200/60000 (85%)] Loss: 0.246904\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3103, Accuracy: 8841/10000, 88.41)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [12800/60000 (21%)] Loss: 0.316487\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [25600/60000 (43%)] Loss: 0.387057\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [38400/60000 (64%)] Loss: 0.400894\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [51200/60000 (85%)] Loss: 0.435308\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3120, Accuracy: 8853/10000, 88.53)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [12800/60000 (21%)] Loss: 0.459440\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [25600/60000 (43%)] Loss: 0.404100\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [38400/60000 (64%)] Loss: 0.493482\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [51200/60000 (85%)] Loss: 0.717872\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3089, Accuracy: 8858/10000, 88.58)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [12800/60000 (21%)] Loss: 0.349777\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [25600/60000 (43%)] Loss: 0.452153\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [38400/60000 (64%)] Loss: 0.270595\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [51200/60000 (85%)] Loss: 0.296577\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3121, Accuracy: 8840/10000, 88.4)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [12800/60000 (21%)] Loss: 0.489391\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [25600/60000 (43%)] Loss: 0.309218\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [38400/60000 (64%)] Loss: 0.409480\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [51200/60000 (85%)] Loss: 0.336631\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3058, Accuracy: 8873/10000, 88.73)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [12800/60000 (21%)] Loss: 0.344963\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [25600/60000 (43%)] Loss: 0.415562\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [38400/60000 (64%)] Loss: 0.377089\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [51200/60000 (85%)] Loss: 0.331977\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3057, Accuracy: 8846/10000, 88.46)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [12800/60000 (21%)] Loss: 0.469154\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [25600/60000 (43%)] Loss: 0.338166\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [38400/60000 (64%)] Loss: 0.230715\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [51200/60000 (85%)] Loss: 0.297016\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3078, Accuracy: 8875/10000, 88.75)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [12800/60000 (21%)] Loss: 0.316614\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [25600/60000 (43%)] Loss: 0.467346\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [38400/60000 (64%)] Loss: 0.358440\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [51200/60000 (85%)] Loss: 0.317816\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3045, Accuracy: 8888/10000, 88.88)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [12800/60000 (21%)] Loss: 0.414366\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [25600/60000 (43%)] Loss: 0.299343\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [38400/60000 (64%)] Loss: 0.387002\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [51200/60000 (85%)] Loss: 0.395878\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3053, Accuracy: 8877/10000, 88.77)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [12800/60000 (21%)] Loss: 0.298172\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [25600/60000 (43%)] Loss: 0.321485\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [38400/60000 (64%)] Loss: 0.390608\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [51200/60000 (85%)] Loss: 0.381871\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3067, Accuracy: 8890/10000, 88.9)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [12800/60000 (21%)] Loss: 0.405018\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [25600/60000 (43%)] Loss: 0.387462\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [38400/60000 (64%)] Loss: 0.379364\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [51200/60000 (85%)] Loss: 0.315313\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2991, Accuracy: 8875/10000, 88.75)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [12800/60000 (21%)] Loss: 0.383394\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [25600/60000 (43%)] Loss: 0.383893\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [38400/60000 (64%)] Loss: 0.407280\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [51200/60000 (85%)] Loss: 0.436870\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2991, Accuracy: 8916/10000, 89.16)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [12800/60000 (21%)] Loss: 0.278260\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [25600/60000 (43%)] Loss: 0.414889\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [38400/60000 (64%)] Loss: 0.401089\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [51200/60000 (85%)] Loss: 0.440861\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3062, Accuracy: 8889/10000, 88.89)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [12800/60000 (21%)] Loss: 0.434613\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [25600/60000 (43%)] Loss: 0.413781\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [38400/60000 (64%)] Loss: 0.375529\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [51200/60000 (85%)] Loss: 0.502070\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3023, Accuracy: 8874/10000, 88.74)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [12800/60000 (21%)] Loss: 0.536090\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [25600/60000 (43%)] Loss: 0.432918\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [38400/60000 (64%)] Loss: 0.433987\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [51200/60000 (85%)] Loss: 0.307257\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3056, Accuracy: 8870/10000, 88.7)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [12800/60000 (21%)] Loss: 0.400824\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [25600/60000 (43%)] Loss: 0.357926\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [38400/60000 (64%)] Loss: 0.328695\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [51200/60000 (85%)] Loss: 0.427238\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3016, Accuracy: 8891/10000, 88.91)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [12800/60000 (21%)] Loss: 0.326770\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [25600/60000 (43%)] Loss: 0.421589\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [38400/60000 (64%)] Loss: 0.315295\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [51200/60000 (85%)] Loss: 0.253868\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3030, Accuracy: 8859/10000, 88.59)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [12800/60000 (21%)] Loss: 0.400174\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [25600/60000 (43%)] Loss: 0.268221\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [38400/60000 (64%)] Loss: 0.320929\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [51200/60000 (85%)] Loss: 0.379186\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3052, Accuracy: 8894/10000, 88.94)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [12800/60000 (21%)] Loss: 0.453921\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [25600/60000 (43%)] Loss: 0.401640\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [38400/60000 (64%)] Loss: 0.534871\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [51200/60000 (85%)] Loss: 0.346532\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3070, Accuracy: 8884/10000, 88.84)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [12800/60000 (21%)] Loss: 0.375574\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [25600/60000 (43%)] Loss: 0.434560\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [38400/60000 (64%)] Loss: 0.424508\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [51200/60000 (85%)] Loss: 0.332743\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3001, Accuracy: 8892/10000, 88.92)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [12800/60000 (21%)] Loss: 0.436893\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [25600/60000 (43%)] Loss: 0.529458\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [38400/60000 (64%)] Loss: 0.341018\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [51200/60000 (85%)] Loss: 0.277996\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3014, Accuracy: 8893/10000, 88.93)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [12800/60000 (21%)] Loss: 0.277119\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [25600/60000 (43%)] Loss: 0.332284\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [38400/60000 (64%)] Loss: 0.447437\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [51200/60000 (85%)] Loss: 0.315670\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2973, Accuracy: 8909/10000, 89.09)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [12800/60000 (21%)] Loss: 0.371940\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [25600/60000 (43%)] Loss: 0.366422\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [38400/60000 (64%)] Loss: 0.364434\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [51200/60000 (85%)] Loss: 0.234038\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2965, Accuracy: 8899/10000, 88.99)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [12800/60000 (21%)] Loss: 0.328157\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [25600/60000 (43%)] Loss: 0.360790\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [38400/60000 (64%)] Loss: 0.322174\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [51200/60000 (85%)] Loss: 0.337763\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3021, Accuracy: 8892/10000, 88.92)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [12800/60000 (21%)] Loss: 0.532042\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [25600/60000 (43%)] Loss: 0.469970\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [38400/60000 (64%)] Loss: 0.490100\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [51200/60000 (85%)] Loss: 0.229841\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2977, Accuracy: 8912/10000, 89.12)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [12800/60000 (21%)] Loss: 0.322648\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [25600/60000 (43%)] Loss: 0.406551\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [38400/60000 (64%)] Loss: 0.318549\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [51200/60000 (85%)] Loss: 0.323052\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3011, Accuracy: 8874/10000, 88.74)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [12800/60000 (21%)] Loss: 0.272013\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [25600/60000 (43%)] Loss: 0.406287\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [38400/60000 (64%)] Loss: 0.375326\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [51200/60000 (85%)] Loss: 0.419823\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2999, Accuracy: 8914/10000, 89.14)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [12800/60000 (21%)] Loss: 0.306924\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [25600/60000 (43%)] Loss: 0.267555\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [38400/60000 (64%)] Loss: 0.359817\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [51200/60000 (85%)] Loss: 0.339237\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2972, Accuracy: 8882/10000, 88.82)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [12800/60000 (21%)] Loss: 0.307276\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [25600/60000 (43%)] Loss: 0.478475\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [38400/60000 (64%)] Loss: 0.445997\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [51200/60000 (85%)] Loss: 0.462058\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2928, Accuracy: 8896/10000, 88.96)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [12800/60000 (21%)] Loss: 0.252990\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [25600/60000 (43%)] Loss: 0.251297\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [38400/60000 (64%)] Loss: 0.245608\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [51200/60000 (85%)] Loss: 0.286580\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2937, Accuracy: 8907/10000, 89.07)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [12800/60000 (21%)] Loss: 0.459157\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [25600/60000 (43%)] Loss: 0.470164\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [38400/60000 (64%)] Loss: 0.271307\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [51200/60000 (85%)] Loss: 0.429969\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2924, Accuracy: 8909/10000, 89.09)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [12800/60000 (21%)] Loss: 0.230752\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [25600/60000 (43%)] Loss: 0.337278\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [38400/60000 (64%)] Loss: 0.549978\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [51200/60000 (85%)] Loss: 0.426774\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2940, Accuracy: 8916/10000, 89.16)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [12800/60000 (21%)] Loss: 0.333335\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [25600/60000 (43%)] Loss: 0.348359\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [38400/60000 (64%)] Loss: 0.297380\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [51200/60000 (85%)] Loss: 0.325463\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2912, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [12800/60000 (21%)] Loss: 0.397811\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [25600/60000 (43%)] Loss: 0.369866\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [38400/60000 (64%)] Loss: 0.383273\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [51200/60000 (85%)] Loss: 0.269847\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2946, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [12800/60000 (21%)] Loss: 0.385505\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [25600/60000 (43%)] Loss: 0.413240\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [38400/60000 (64%)] Loss: 0.346329\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [51200/60000 (85%)] Loss: 0.358391\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2918, Accuracy: 8920/10000, 89.2)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [12800/60000 (21%)] Loss: 0.364183\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [25600/60000 (43%)] Loss: 0.555513\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [38400/60000 (64%)] Loss: 0.357444\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [51200/60000 (85%)] Loss: 0.459110\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2955, Accuracy: 8933/10000, 89.33)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [12800/60000 (21%)] Loss: 0.572920\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [25600/60000 (43%)] Loss: 0.298102\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [38400/60000 (64%)] Loss: 0.269612\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [51200/60000 (85%)] Loss: 0.350049\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2925, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [12800/60000 (21%)] Loss: 0.326394\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [25600/60000 (43%)] Loss: 0.285683\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [38400/60000 (64%)] Loss: 0.308082\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [51200/60000 (85%)] Loss: 0.317443\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2954, Accuracy: 8915/10000, 89.15)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [12800/60000 (21%)] Loss: 0.332017\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [25600/60000 (43%)] Loss: 0.584337\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [38400/60000 (64%)] Loss: 0.295038\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [51200/60000 (85%)] Loss: 0.350227\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2982, Accuracy: 8914/10000, 89.14)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [12800/60000 (21%)] Loss: 0.273183\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [25600/60000 (43%)] Loss: 0.345203\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [38400/60000 (64%)] Loss: 0.424715\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [51200/60000 (85%)] Loss: 0.307842\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2918, Accuracy: 8921/10000, 89.21)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [12800/60000 (21%)] Loss: 0.403539\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [25600/60000 (43%)] Loss: 0.209393\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [38400/60000 (64%)] Loss: 0.283071\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [51200/60000 (85%)] Loss: 0.372288\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2946, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [12800/60000 (21%)] Loss: 0.451221\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [25600/60000 (43%)] Loss: 0.320394\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [38400/60000 (64%)] Loss: 0.439384\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [51200/60000 (85%)] Loss: 0.252537\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2978, Accuracy: 8919/10000, 89.19)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [12800/60000 (21%)] Loss: 0.386817\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [25600/60000 (43%)] Loss: 0.451141\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [38400/60000 (64%)] Loss: 0.374609\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [51200/60000 (85%)] Loss: 0.300178\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2925, Accuracy: 8940/10000, 89.4)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [12800/60000 (21%)] Loss: 0.308253\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [25600/60000 (43%)] Loss: 0.307126\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [38400/60000 (64%)] Loss: 0.381043\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [51200/60000 (85%)] Loss: 0.323941\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2903, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [12800/60000 (21%)] Loss: 0.268061\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [25600/60000 (43%)] Loss: 0.356558\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [38400/60000 (64%)] Loss: 0.316394\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [51200/60000 (85%)] Loss: 0.444125\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2965, Accuracy: 8912/10000, 89.12)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [12800/60000 (21%)] Loss: 0.314189\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [25600/60000 (43%)] Loss: 0.452702\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [38400/60000 (64%)] Loss: 0.470834\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [51200/60000 (85%)] Loss: 0.306546\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2948, Accuracy: 8915/10000, 89.15)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [12800/60000 (21%)] Loss: 0.271236\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [25600/60000 (43%)] Loss: 0.316136\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [38400/60000 (64%)] Loss: 0.360888\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [51200/60000 (85%)] Loss: 0.374910\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2957, Accuracy: 8912/10000, 89.12)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [12800/60000 (21%)] Loss: 0.372041\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [25600/60000 (43%)] Loss: 0.330489\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [38400/60000 (64%)] Loss: 0.275257\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [51200/60000 (85%)] Loss: 0.471137\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2954, Accuracy: 8901/10000, 89.01)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [12800/60000 (21%)] Loss: 0.320914\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [25600/60000 (43%)] Loss: 0.328749\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [38400/60000 (64%)] Loss: 0.558718\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [51200/60000 (85%)] Loss: 0.433290\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2971, Accuracy: 8898/10000, 88.98)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [12800/60000 (21%)] Loss: 0.404926\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [25600/60000 (43%)] Loss: 0.361285\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [38400/60000 (64%)] Loss: 0.232506\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [51200/60000 (85%)] Loss: 0.321794\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2959, Accuracy: 8908/10000, 89.08)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [12800/60000 (21%)] Loss: 0.408446\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [25600/60000 (43%)] Loss: 0.464957\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [38400/60000 (64%)] Loss: 0.398855\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [51200/60000 (85%)] Loss: 0.337778\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2964, Accuracy: 8887/10000, 88.87)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [12800/60000 (21%)] Loss: 0.428620\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [25600/60000 (43%)] Loss: 0.464869\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [38400/60000 (64%)] Loss: 0.395905\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [51200/60000 (85%)] Loss: 0.431700\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2914, Accuracy: 8918/10000, 89.18)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [12800/60000 (21%)] Loss: 0.331902\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [25600/60000 (43%)] Loss: 0.346695\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [38400/60000 (64%)] Loss: 0.335131\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [51200/60000 (85%)] Loss: 0.371559\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3032, Accuracy: 8863/10000, 88.63)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [12800/60000 (21%)] Loss: 0.407917\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [25600/60000 (43%)] Loss: 0.300513\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [38400/60000 (64%)] Loss: 0.313024\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [51200/60000 (85%)] Loss: 0.420386\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2944, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [12800/60000 (21%)] Loss: 0.429144\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [25600/60000 (43%)] Loss: 0.405923\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [38400/60000 (64%)] Loss: 0.393889\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [51200/60000 (85%)] Loss: 0.334599\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2913, Accuracy: 8947/10000, 89.47)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [12800/60000 (21%)] Loss: 0.457005\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [25600/60000 (43%)] Loss: 0.405288\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [38400/60000 (64%)] Loss: 0.358333\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [51200/60000 (85%)] Loss: 0.352362\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2923, Accuracy: 8911/10000, 89.11)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [12800/60000 (21%)] Loss: 0.297865\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [25600/60000 (43%)] Loss: 0.378790\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [38400/60000 (64%)] Loss: 0.319495\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [51200/60000 (85%)] Loss: 0.356056\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3010, Accuracy: 8867/10000, 88.67)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [12800/60000 (21%)] Loss: 0.400637\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [25600/60000 (43%)] Loss: 0.321659\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [38400/60000 (64%)] Loss: 0.389611\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [51200/60000 (85%)] Loss: 0.314665\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2899, Accuracy: 8931/10000, 89.31)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [12800/60000 (21%)] Loss: 0.276085\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [25600/60000 (43%)] Loss: 0.201693\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [38400/60000 (64%)] Loss: 0.361413\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [51200/60000 (85%)] Loss: 0.269575\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2930, Accuracy: 8910/10000, 89.1)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [12800/60000 (21%)] Loss: 0.400274\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [25600/60000 (43%)] Loss: 0.455223\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [38400/60000 (64%)] Loss: 0.453818\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [51200/60000 (85%)] Loss: 0.333927\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2904, Accuracy: 8943/10000, 89.43)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [12800/60000 (21%)] Loss: 0.447177\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [25600/60000 (43%)] Loss: 0.251240\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [38400/60000 (64%)] Loss: 0.181807\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [51200/60000 (85%)] Loss: 0.346273\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2932, Accuracy: 8924/10000, 89.24)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [12800/60000 (21%)] Loss: 0.282141\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [25600/60000 (43%)] Loss: 0.461351\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [38400/60000 (64%)] Loss: 0.411939\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [51200/60000 (85%)] Loss: 0.322635\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2890, Accuracy: 8939/10000, 89.39)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [12800/60000 (21%)] Loss: 0.384548\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [25600/60000 (43%)] Loss: 0.275913\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [38400/60000 (64%)] Loss: 0.432580\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [51200/60000 (85%)] Loss: 0.523996\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2920, Accuracy: 8929/10000, 89.29)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [12800/60000 (21%)] Loss: 0.396972\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [25600/60000 (43%)] Loss: 0.286147\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [38400/60000 (64%)] Loss: 0.605653\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [51200/60000 (85%)] Loss: 0.430332\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2891, Accuracy: 8941/10000, 89.41)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [12800/60000 (21%)] Loss: 0.358937\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [25600/60000 (43%)] Loss: 0.289340\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [38400/60000 (64%)] Loss: 0.476093\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [51200/60000 (85%)] Loss: 0.269411\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2888, Accuracy: 8957/10000, 89.57)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [12800/60000 (21%)] Loss: 0.308657\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [25600/60000 (43%)] Loss: 0.411374\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [38400/60000 (64%)] Loss: 0.323359\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [51200/60000 (85%)] Loss: 0.440602\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2920, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [12800/60000 (21%)] Loss: 0.277151\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [25600/60000 (43%)] Loss: 0.458091\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [38400/60000 (64%)] Loss: 0.246828\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [51200/60000 (85%)] Loss: 0.341924\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2901, Accuracy: 8942/10000, 89.42)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [12800/60000 (21%)] Loss: 0.300668\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [25600/60000 (43%)] Loss: 0.359393\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [38400/60000 (64%)] Loss: 0.207842\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [51200/60000 (85%)] Loss: 0.347402\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2866, Accuracy: 8953/10000, 89.53)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [12800/60000 (21%)] Loss: 0.380928\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [25600/60000 (43%)] Loss: 0.331966\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [38400/60000 (64%)] Loss: 0.364212\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [51200/60000 (85%)] Loss: 0.324065\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2877, Accuracy: 8946/10000, 89.46)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [12800/60000 (21%)] Loss: 0.376610\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [25600/60000 (43%)] Loss: 0.431485\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [38400/60000 (64%)] Loss: 0.277322\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [51200/60000 (85%)] Loss: 0.393579\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2896, Accuracy: 8937/10000, 89.37)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [12800/60000 (21%)] Loss: 0.299926\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [25600/60000 (43%)] Loss: 0.272140\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [38400/60000 (64%)] Loss: 0.348477\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [51200/60000 (85%)] Loss: 0.450787\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2918, Accuracy: 8942/10000, 89.42)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [12800/60000 (21%)] Loss: 0.438558\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [25600/60000 (43%)] Loss: 0.271443\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [38400/60000 (64%)] Loss: 0.385347\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [51200/60000 (85%)] Loss: 0.477691\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2950, Accuracy: 8904/10000, 89.04)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 99 [12800/60000 (21%)] Loss: 0.260280\u001b[0m\n",
      "\u001b[34mTrain Epoch: 99 [25600/60000 (43%)] Loss: 0.470011\u001b[0m\n",
      "\u001b[34mTrain Epoch: 99 [38400/60000 (64%)] Loss: 0.343432\u001b[0m\n",
      "\n",
      "2021-12-22 00:53:14 Uploading - Uploading generated training modelLowGPUUtilization: IssuesFound\n",
      "ProfilerReport: InProgress\n",
      "\u001b[34mTrain Epoch: 99 [51200/60000 (85%)] Loss: 0.557614\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2907, Accuracy: 8926/10000, 89.26)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 100 [12800/60000 (21%)] Loss: 0.223838\u001b[0m\n",
      "\u001b[34mTrain Epoch: 100 [25600/60000 (43%)] Loss: 0.363347\u001b[0m\n",
      "\u001b[34mTrain Epoch: 100 [38400/60000 (64%)] Loss: 0.258954\u001b[0m\n",
      "\u001b[34mTrain Epoch: 100 [51200/60000 (85%)] Loss: 0.373747\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2860, Accuracy: 8935/10000, 89.35)\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mINFO:__main__:Start training ...\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.5407, Accuracy: 7972/10000, 79.72)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.4667, Accuracy: 8311/10000, 83.11)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.4316, Accuracy: 8426/10000, 84.26)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.4136, Accuracy: 8512/10000, 85.12)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3897, Accuracy: 8568/10000, 85.68)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3797, Accuracy: 8603/10000, 86.03)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3697, Accuracy: 8605/10000, 86.05)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3619, Accuracy: 8686/10000, 86.86)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3543, Accuracy: 8690/10000, 86.9)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3465, Accuracy: 8712/10000, 87.12)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3388, Accuracy: 8745/10000, 87.45)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3380, Accuracy: 8744/10000, 87.44)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3391, Accuracy: 8776/10000, 87.76)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3291, Accuracy: 8807/10000, 88.07)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3314, Accuracy: 8790/10000, 87.9)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3309, Accuracy: 8805/10000, 88.05)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3187, Accuracy: 8820/10000, 88.2)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3200, Accuracy: 8829/10000, 88.29)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3244, Accuracy: 8835/10000, 88.35)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3190, Accuracy: 8819/10000, 88.19)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3187, Accuracy: 8834/10000, 88.34)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3136, Accuracy: 8830/10000, 88.3)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3141, Accuracy: 8842/10000, 88.42)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3178, Accuracy: 8826/10000, 88.26)\u001b[0m\n",
      "\u001b[34m2021-12-22 00:53:11,242 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3143, Accuracy: 8855/10000, 88.55)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3081, Accuracy: 8885/10000, 88.85)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3103, Accuracy: 8841/10000, 88.41)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3120, Accuracy: 8853/10000, 88.53)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3089, Accuracy: 8858/10000, 88.58)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3121, Accuracy: 8840/10000, 88.4)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3058, Accuracy: 8873/10000, 88.73)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3057, Accuracy: 8846/10000, 88.46)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3078, Accuracy: 8875/10000, 88.75)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3045, Accuracy: 8888/10000, 88.88)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3053, Accuracy: 8877/10000, 88.77)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3067, Accuracy: 8890/10000, 88.9)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2991, Accuracy: 8875/10000, 88.75)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2991, Accuracy: 8916/10000, 89.16)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3062, Accuracy: 8889/10000, 88.89)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3023, Accuracy: 8874/10000, 88.74)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3056, Accuracy: 8870/10000, 88.7)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3016, Accuracy: 8891/10000, 88.91)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3030, Accuracy: 8859/10000, 88.59)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3052, Accuracy: 8894/10000, 88.94)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3070, Accuracy: 8884/10000, 88.84)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3001, Accuracy: 8892/10000, 88.92)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3014, Accuracy: 8893/10000, 88.93)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2973, Accuracy: 8909/10000, 89.09)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2965, Accuracy: 8899/10000, 88.99)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3021, Accuracy: 8892/10000, 88.92)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2977, Accuracy: 8912/10000, 89.12)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3011, Accuracy: 8874/10000, 88.74)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2999, Accuracy: 8914/10000, 89.14)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2972, Accuracy: 8882/10000, 88.82)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2928, Accuracy: 8896/10000, 88.96)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2937, Accuracy: 8907/10000, 89.07)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2924, Accuracy: 8909/10000, 89.09)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2940, Accuracy: 8916/10000, 89.16)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2912, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2946, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2918, Accuracy: 8920/10000, 89.2)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2955, Accuracy: 8933/10000, 89.33)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2925, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2954, Accuracy: 8915/10000, 89.15)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2982, Accuracy: 8914/10000, 89.14)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2918, Accuracy: 8921/10000, 89.21)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2946, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2978, Accuracy: 8919/10000, 89.19)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2925, Accuracy: 8940/10000, 89.4)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2903, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2965, Accuracy: 8912/10000, 89.12)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2948, Accuracy: 8915/10000, 89.15)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2957, Accuracy: 8912/10000, 89.12)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2954, Accuracy: 8901/10000, 89.01)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2971, Accuracy: 8898/10000, 88.98)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2959, Accuracy: 8908/10000, 89.08)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2964, Accuracy: 8887/10000, 88.87)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2914, Accuracy: 8918/10000, 89.18)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3032, Accuracy: 8863/10000, 88.63)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2944, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2913, Accuracy: 8947/10000, 89.47)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2923, Accuracy: 8911/10000, 89.11)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.3010, Accuracy: 8867/10000, 88.67)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2899, Accuracy: 8931/10000, 89.31)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2930, Accuracy: 8910/10000, 89.1)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2904, Accuracy: 8943/10000, 89.43)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2932, Accuracy: 8924/10000, 89.24)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2890, Accuracy: 8939/10000, 89.39)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2920, Accuracy: 8929/10000, 89.29)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2891, Accuracy: 8941/10000, 89.41)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2888, Accuracy: 8957/10000, 89.57)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2920, Accuracy: 8927/10000, 89.27)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2901, Accuracy: 8942/10000, 89.42)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2866, Accuracy: 8953/10000, 89.53)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2877, Accuracy: 8946/10000, 89.46)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2896, Accuracy: 8937/10000, 89.37)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2918, Accuracy: 8942/10000, 89.42)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2950, Accuracy: 8904/10000, 89.04)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2907, Accuracy: 8926/10000, 89.26)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.2860, Accuracy: 8935/10000, 89.35)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model\u001b[0m\n",
      "\n",
      "2021-12-22 00:57:36 Completed - Training job completed\n",
      "Training seconds: 894\n",
      "Billable seconds: 894\n"
     ]
    }
   ],
   "source": [
    "job_name=estimator.latest_training_job.name\n",
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b108ee",
   "metadata": {},
   "source": [
    "### Download profiler report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d48ecc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_output_path = estimator.output_path + '/' + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "rule_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3832729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22 00:29:06     424537 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-report.html\n",
      "2021-12-22 00:29:06     281005 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-report.ipynb\n",
      "2021-12-22 00:29:00        536 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/BatchSize.json\n",
      "2021-12-22 00:29:00      11696 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "2021-12-22 00:29:00       2041 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/Dataloader.json\n",
      "2021-12-22 00:29:00        130 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "2021-12-22 00:29:01      11070 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json\n",
      "2021-12-22 00:29:01        313 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json\n",
      "2021-12-22 00:29:01        351 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "2021-12-22 00:29:01        234 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "2021-12-22 00:29:01       1268 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "2021-12-22 00:29:01        596 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "2021-12-22 00:29:01       2801 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {rule_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00bfed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./profiler', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1a48641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json to profiler/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/BatchSize.json to profiler/ProfilerReport/profiler-output/profiler-reports/BatchSize.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json to profiler/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json to profiler/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json to profiler/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json to profiler/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json to profiler/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json to profiler/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json to profiler/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-report.html to profiler/ProfilerReport/profiler-output/profiler-report.html\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-report.ipynb to profiler/ProfilerReport/profiler-output/profiler-report.ipynb\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json to profiler/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-22-00-15-45-032/rule-output/ProfilerReport/profiler-output/profiler-reports/Dataloader.json to profiler/ProfilerReport/profiler-output/profiler-reports/Dataloader.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp {rule_output_path} ./profiler --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be038f",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ea9bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tensorboard==2.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (1.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (0.37.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (3.19.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (58.5.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (2.26.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (1.21.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.3) (1.35.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.3) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.3) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.3) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.3) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard==2.3) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.3) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.3) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.3) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.3) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.3) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.3) (3.10.0.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.3) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.3) (3.1.1)\n",
      "\u001b[33mWARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/PyYAML-6.0.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tensorboard.html\n",
    "!pip install tensorboard==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d44bbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n"
     ]
    }
   ],
   "source": [
    "aws_region = sagemaker_session.boto_region_name\n",
    "!AWS_REGION={aws_region}\n",
    "!echo tensorboard --logdir {tensorboard_logs_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd865dc",
   "metadata": {},
   "source": [
    "[**Click here to access TensorBoard instance**](/proxy/6006/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a262fa9",
   "metadata": {},
   "source": [
    "SageMaker notebook이 아닌 환경에서 접속하려면? `https://<notebook instance hostname>/proxy/6006/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d027c9",
   "metadata": {},
   "source": [
    "# Screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2924be",
   "metadata": {},
   "source": [
    "![tensorboard](image/01.tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad3000",
   "metadata": {},
   "source": [
    "![SM-experiments](image/02.SM-experiments.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c0780",
   "metadata": {},
   "source": [
    "![SM-debugger](image/03.SM-debugger.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1d256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p37",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
