{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0079f8d8",
   "metadata": {},
   "source": [
    "# Fashion-MNIST PyTorch image classification w/ Tensorboard\n",
    "Source\n",
    "- https://tutorials.pytorch.kr/intermediate/tensorboard_tutorial.html\n",
    "- https://github.com/aws/amazon-sagemaker-examples/blob/master/frameworks/pytorch/get_started_mnist_train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7fa9b",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89a174dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install_needed = True\n",
    "install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc4e60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U 'sagemaker[local]'\n",
    "    !{sys.executable} -m pip install -U sagemaker-experiments # SageMaker Experiments SDK \n",
    "    !{sys.executable} -m pip install -U sagemaker             # SageMaker Python SDK\n",
    "    !/bin/bash ./local/local_mode_setup.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbbcc2f",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6885a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5caea834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24afee0",
   "metadata": {},
   "source": [
    "## Set up the SageMaker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33161b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-ap-northeast-2-889750940888\n",
      "SageMaker ver: 2.70.0\n",
      "Tensorboard log path: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from smexperiments.experiment import Experiment ### SM Experiment\n",
    "from smexperiments.trial import Trial           ### SM Experiment\n",
    "\n",
    "from sagemaker.debugger import TensorBoardOutputConfig ### For TensorBoard \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"tensorboard_pytorch_fashion_mnist\"\n",
    "tensorboard_logs_path = \"s3://{}/{}/logs\".format(bucket, prefix) ### For TensorBoard\n",
    "output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "print(\"Bucket: {}\".format(bucket))\n",
    "print(\"SageMaker ver: \" + sagemaker.__version__)\n",
    "print(\"Tensorboard log path: {}\".format(tensorboard_logs_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fd9a6",
   "metadata": {},
   "source": [
    "## Uploading the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7f9182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/t10k-labels-idx1-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte\n",
      "upload: data/FashionMNIST/raw/train-labels-idx1-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte\n",
      "upload: data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/t10k-images-idx3-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte\n",
      "upload: data/FashionMNIST/raw/train-images-idx3-ubyte.gz to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte.gz\n",
      "upload: data/FashionMNIST/raw/train-images-idx3-ubyte to s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./data/FashionMNIST/raw s3://{bucket}/{prefix}/data --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4f2c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = 's3://{}/{}/data'.format(bucket, prefix)\n",
    "test_location = 's3://{}/{}/data'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cde6047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-10 03:21:06    7840016 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte\n",
      "2021-12-10 03:21:06    4422102 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte.gz\n",
      "2021-12-10 03:21:06      10008 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte\n",
      "2021-12-10 03:21:06       5148 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "2021-12-10 03:21:06   47040016 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte\n",
      "2021-12-10 03:21:06   26421880 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte.gz\n",
      "2021-12-10 03:21:06      60008 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte\n",
      "2021-12-10 03:21:06      29515 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {train_location} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac474dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-10 03:21:06    7840016 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte\n",
      "2021-12-10 03:21:06    4422102 tensorboard_pytorch_fashion_mnist/data/t10k-images-idx3-ubyte.gz\n",
      "2021-12-10 03:21:06      10008 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte\n",
      "2021-12-10 03:21:06       5148 tensorboard_pytorch_fashion_mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "2021-12-10 03:21:06   47040016 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte\n",
      "2021-12-10 03:21:06   26421880 tensorboard_pytorch_fashion_mnist/data/train-images-idx3-ubyte.gz\n",
      "2021-12-10 03:21:06      60008 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte\n",
      "2021-12-10 03:21:06      29515 tensorboard_pytorch_fashion_mnist/data/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {test_location} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6cfd8e",
   "metadata": {},
   "source": [
    "## Local mode training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3175d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.local import LocalSession\n",
    "# sagemaker_session = LocalSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2433e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import TensorBoardOutputConfig ### For TensorBoard \n",
    "\n",
    "# An error occurred (ValidationException) when calling the CreateTrainingJob operation:\n",
    "# \"LocalPath\" of \"TensorBoardOutputConfig\" cannot start with the following reserved path: [/opt/ml, /tmp, /usr/local/nvidia]\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_logs_path,\n",
    "    container_local_output_path='/pytorch/tensors'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1925ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_local = {\"batch-size\": 128,\n",
    "                         \"epochs\": 1,\n",
    "                         \"learning-rate\": 1e-3,\n",
    "                         \"log-interval\": 100,\n",
    "                         \"tensorboard-logs-path\": tensorboard_logs_path} # Not working in local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "906fb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local_mode to be True if you want to run the training script\n",
    "# on the machine that runs this notebook\n",
    "\n",
    "local_mode = True\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.c5.xlarge\"\n",
    "\n",
    "est_local = PyTorch(\n",
    "            entry_point=\"train.py\",\n",
    "            source_dir=\"code\",  # directory of your training script\n",
    "            role=role,\n",
    "            framework_version=\"1.8.1\",\n",
    "            py_version=\"py3\",\n",
    "            instance_type=instance_type,\n",
    "            instance_count=1,\n",
    "            output_path=output_path,\n",
    "            hyperparameters=hyperparameters_local,\n",
    "            tensorboard_output_config=tensorboard_output_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "290ab370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2021-12-10-03-21-18-149\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-rs61j:\n",
      "    command: train\n",
      "    container_name: t8imoy5bnm-algo-1-rs61j\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-training:1.8.1-cpu-py3\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-rs61j\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp9q0ols2m/algo-1-rs61j/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmp9q0ols2m/algo-1-rs61j/input:/opt/ml/input\n",
      "    - /tmp/tmp9q0ols2m/algo-1-rs61j/output:/opt/ml/output\n",
      "    - /tmp/tmp9q0ols2m/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /tmp/tmpdh8tjj9r:/opt/ml/input/data/training\n",
      "    - /tmp/tmp6n8tzhe6:/opt/ml/input/data/testing\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmp9q0ols2m/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating t8imoy5bnm-algo-1-rs61j ... \n",
      "Creating t8imoy5bnm-algo-1-rs61j ... done\n",
      "Attaching to t8imoy5bnm-algo-1-rs61j\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:22,970 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:22,972 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:22,982 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:22,985 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:23,125 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Collecting tensorboard<2.4\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "     |████████████████████████████████| 6.8 MB 2.1 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.0.2)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (0.37.0)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (49.6.0.post20210108)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.19.1)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.26.0)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (3.18.1)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Collecting absl-py>=0.4\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "     |████████████████████████████████| 126 kB 70.4 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 83.5 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hCollecting grpcio>=1.24.3\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading grpcio-1.42.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 50.7 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hCollecting markdown>=2.6.8\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 8.8 MB/s             \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 44.8 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.16.0)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 68.5 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (4.7.2)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Collecting requests-oauthlib>=0.7.0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (4.8.1)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.0.4)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2021.5.30)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (3.2)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (1.26.7)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.4->-r requirements.txt (line 1)) (0.8)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.6.0)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (0.4.8)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Collecting oauthlib>=3.0.0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m   Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "     |████████████████████████████████| 146 kB 61.5 MB/s            \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \u001b[?25hInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Successfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.42.0 markdown-3.3.6 oauthlib-3.1.1 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.3.0 tensorboard-plugin-wit-1.8.0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:29,196 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:29,208 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:29,218 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:29,227 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Training Env:\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"testing\": \"/opt/ml/input/data/testing\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     },\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"current_host\": \"algo-1-rs61j\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"algo-1-rs61j\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     ],\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"batch-size\": 128,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"learning-rate\": 0.001,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"log-interval\": 100,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"tensorboard-logs-path\": \"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     },\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"training\": {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         },\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"testing\": {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         }\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     },\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"job_name\": \"pytorch-training-2021-12-10-03-21-18-149\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"master_hostname\": \"algo-1-rs61j\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/pytorch-training-2021-12-10-03-21-18-149/source/sourcedir.tar.gz\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"current_host\": \"algo-1-rs61j\",\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m             \"algo-1-rs61j\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m         ]\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     },\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m }\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Environment variables:\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HOSTS=[\"algo-1-rs61j\"]\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HPS={\"batch-size\":128,\"epochs\":1,\"learning-rate\":0.001,\"log-interval\":100,\"tensorboard-logs-path\":\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"}\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-rs61j\",\"hosts\":[\"algo-1-rs61j\"]}\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_INPUT_DATA_CONFIG={\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_CHANNELS=[\"testing\",\"training\"]\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_CURRENT_HOST=algo-1-rs61j\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/pytorch-training-2021-12-10-03-21-18-149/source/sourcedir.tar.gz\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-rs61j\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-rs61j\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":1,\"learning-rate\":0.001,\"log-interval\":100,\"tensorboard-logs-path\":\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-12-10-03-21-18-149\",\"log_level\":20,\"master_hostname\":\"algo-1-rs61j\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/pytorch-training-2021-12-10-03-21-18-149/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-rs61j\",\"hosts\":[\"algo-1-rs61j\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"1\",\"--learning-rate\",\"0.001\",\"--log-interval\",\"100\",\"--tensorboard-logs-path\",\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"]\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_CHANNEL_TESTING=/opt/ml/input/data/testing\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HP_BATCH-SIZE=128\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HP_LEARNING-RATE=0.001\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HP_LOG-INTERVAL=100\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m SM_HP_TENSORBOARD-LOGS-PATH=s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m /opt/conda/bin/python3.6 train.py --batch-size 128 --epochs 1 --learning-rate 0.001 --log-interval 100 --tensorboard-logs-path s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m [2021-12-10 03:21:31.292 algo-1-rs61j:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m [2021-12-10 03:21:31.487 algo-1-rs61j:33 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Start training ...\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Train Epoch: 1 [12800/60000 (21%)] Loss: 0.975204\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Train Epoch: 1 [25600/60000 (43%)] Loss: 0.789189\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Train Epoch: 1 [38400/60000 (64%)] Loss: 0.656050\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Train Epoch: 1 [51200/60000 (85%)] Loss: 0.703340\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Test set: Average loss: 0.5355, Accuracy: 7964/10000, 79.64)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m Saving the model\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m INFO:__main__:Start training ...\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m INFO:__main__:Test set: Average loss: 0.5355, Accuracy: 7964/10000, 79.64)\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m INFO:__main__:Saving the model\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m \n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j |\u001b[0m 2021-12-10 03:21:36,954 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mt8imoy5bnm-algo-1-rs61j exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "channels = {\"training\": train_location, \"testing\": test_location}\n",
    "est_local.fit(inputs=channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6d09f",
   "metadata": {},
   "source": [
    "## Managed training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb643a11",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cbcc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[\n",
    "                                              {\n",
    "                                                  'Key': 'modelname',\n",
    "                                                  'Value': 'fashion-mnist'\n",
    "                                              },\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0fa3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, i_type, i_cnt, spot):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    \n",
    "    algo = 'dp'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_tag = 'test'\n",
    "    \n",
    "    if i_type == 'ml.p3.16xlarge':\n",
    "        i_tag = 'p3'\n",
    "    elif i_type == 'ml.p2.8xlarge':\n",
    "        i_tag = 'p2'\n",
    "    elif i_type == 'ml.p3dn.24xlarge':\n",
    "        i_tag = 'p3dn'\n",
    "    elif i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'\n",
    "    else:\n",
    "        i_tag = 'others'\n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd439534",
   "metadata": {},
   "source": [
    "### Debugger rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90fb88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bfc5a",
   "metadata": {},
   "source": [
    "### Debugger Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f427591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122525e",
   "metadata": {},
   "source": [
    "### Training environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3192436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{'Name': 'average loss',\n",
    "                       'Regex': 'Average loss: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'accuracy',\n",
    "                       'Regex': 'Accuracy: [0-9]+/[0-9]+, ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3b5ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metric_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dab94074",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"batch-size\": 128,\n",
    "                   \"epochs\": 100,\n",
    "                   \"learning-rate\": 1e-3,\n",
    "                   \"log-interval\": 100,\n",
    "                   \"tensorboard-logs-path\": tensorboard_logs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16e48d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local_mode to be True if you want to run the training script\n",
    "# on the machine that runs this notebook\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "instance_count = 1\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "            entry_point=\"train.py\",\n",
    "            source_dir=\"code\",  # directory of your training script\n",
    "            role=role,\n",
    "            framework_version=\"1.8.1\",\n",
    "            py_version=\"py3\",\n",
    "            instance_type=instance_type,\n",
    "            instance_count=instance_count,\n",
    "            output_path=output_path,\n",
    "            hyperparameters=hyperparameters,\n",
    "            tensorboard_output_config=tensorboard_output_config,\n",
    "            base_job_name='pytorch-tensorboard',\n",
    "            metric_definitions=metric_definitions,\n",
    "            profiler_config=profiler_config,\n",
    "            rules=rules,\n",
    "            disable_profiler=False # default: False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21fd8df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-tensorboard-others-1-dp-d-1210-03211639106518'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'pytorch-tensorboard'\n",
    "do_spot_training=False\n",
    "\n",
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, instance_type, instance_count, do_spot_training)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51b085ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-tensorboard-2021-12-10-03-22-01-596\n"
     ]
    }
   ],
   "source": [
    "channels = {\"training\": train_location, \"testing\": test_location}\n",
    "estimator.fit(inputs=channels,\n",
    "              experiment_config={\n",
    "                  'TrialName': job_name,\n",
    "                  'TrialComponentDisplayName': job_name,\n",
    "                },\n",
    "              wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39103aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-10 03:22:01 Starting - Starting the training job...\n",
      "2021-12-10 03:22:17 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2021-12-10 03:23:33 Starting - Preparing the instances for training.........\n",
      "2021-12-10 03:25:03 Downloading - Downloading input data\n",
      "2021-12-10 03:25:03 Training - Downloading the training image...........................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-12-10 03:29:25,856 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-12-10 03:29:25,878 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-12-10 03:29:25,886 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-12-10 03:29:26,297 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting tensorboard<2.4\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (3.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.42.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (0.36.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.4->-r requirements.txt (line 1)) (2.26.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (4.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.4->-r requirements.txt (line 1)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.4->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.4->-r requirements.txt (line 1)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.4->-r requirements.txt (line 1)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.42.0 markdown-3.3.6 oauthlib-3.1.1 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.3.0 tensorboard-plugin-wit-1.8.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2021-12-10 03:29:34,150 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"log-interval\": 100,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"tensorboard-logs-path\": \"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\",\n",
      "        \"epochs\": 100\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-tensorboard-2021-12-10-03-22-01-596\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/pytorch-tensorboard-2021-12-10-03-22-01-596/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":100,\"learning-rate\":0.001,\"log-interval\":100,\"tensorboard-logs-path\":\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/pytorch-tensorboard-2021-12-10-03-22-01-596/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":100,\"learning-rate\":0.001,\"log-interval\":100,\"tensorboard-logs-path\":\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-tensorboard-2021-12-10-03-22-01-596\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/pytorch-tensorboard-2021-12-10-03-22-01-596/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"100\",\"--learning-rate\",\"0.001\",\"--log-interval\",\"100\",\"--tensorboard-logs-path\",\"s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_TENSORBOARD-LOGS-PATH=s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch-size 128 --epochs 100 --learning-rate 0.001 --log-interval 100 --tensorboard-logs-path s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/logs\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:38.710 algo-1:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:38.786 algo-1:32 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:38.788 algo-1:32 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:38.791 algo-1:32 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:38.791 algo-1:32 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mStart training ...\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.165 algo-1:32 INFO hook.py:591] name:conv1.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.165 algo-1:32 INFO hook.py:591] name:conv1.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.166 algo-1:32 INFO hook.py:591] name:conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.166 algo-1:32 INFO hook.py:591] name:conv2.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.166 algo-1:32 INFO hook.py:591] name:fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.167 algo-1:32 INFO hook.py:591] name:fc1.bias count_params:50\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.167 algo-1:32 INFO hook.py:591] name:fc2.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.167 algo-1:32 INFO hook.py:591] name:fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.168 algo-1:32 INFO hook.py:593] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.168 algo-1:32 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.170 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/prestepzero-*-start-1639106978787202.0_global-0-stepstart-1639106983169879.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:43.185 algo-1:32 INFO hook.py:488] Hook is writing from the hook with pid: 32\u001b[0m\n",
      "\n",
      "2021-12-10 03:30:05 Training - Training image download completed. Training in progress.\u001b[34m[2021-12-10 03:29:51.824 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-0-stepstart-1639106983181763.8_global-0-forwardpassend-1639106991823621.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:52.319 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-0-forwardpassend-1639106991826557.0_global-1-stepstart-1639106992318937.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:52.892 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-1-stepstart-1639106992323990.8_global-1-forwardpassend-1639106992891895.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:52.918 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-1-forwardpassend-1639106992894449.5_global-2-stepstart-1639106992918318.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:53.471 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-2-stepstart-1639106992921233.5_global-2-forwardpassend-1639106993471128.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:53.497 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-2-forwardpassend-1639106993473445.0_global-3-stepstart-1639106993496607.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:54.015 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-3-stepstart-1639106993499312.8_global-3-forwardpassend-1639106994014878.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:54.041 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-3-forwardpassend-1639106994017169.0_global-4-stepstart-1639106994040532.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:54.554 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-4-stepstart-1639106994042873.0_global-4-forwardpassend-1639106994554262.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:54.579 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-4-forwardpassend-1639106994556475.5_global-5-stepstart-1639106994578955.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:55.110 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-5-stepstart-1639106994581110.5_global-5-forwardpassend-1639106995110094.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:55.136 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-5-forwardpassend-1639106995112350.0_global-6-stepstart-1639106995135978.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:55.650 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-6-stepstart-1639106995137999.5_global-6-forwardpassend-1639106995647705.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:55.674 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-6-forwardpassend-1639106995651671.5_global-7-stepstart-1639106995673763.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:56.192 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-7-stepstart-1639106995676228.8_global-7-forwardpassend-1639106996191822.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:56.217 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-7-forwardpassend-1639106996193747.0_global-8-stepstart-1639106996216703.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:56.725 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-8-stepstart-1639106996218898.8_global-8-forwardpassend-1639106996724462.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:56.752 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-8-forwardpassend-1639106996727064.0_global-9-stepstart-1639106996751068.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:57.402 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-9-stepstart-1639106996753630.2_global-9-forwardpassend-1639106997401407.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-10 03:29:57.429 algo-1:32 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/32-algo-1/global-9-forwardpassend-1639106997404069.5_global-10-stepstart-1639106997429299.2/python_stats.\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)] Loss: 1.033944\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)] Loss: 0.747328\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)] Loss: 0.679330\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)] Loss: 0.770375\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5376, Accuracy: 7981/10000, 79.81)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)] Loss: 0.565951\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)] Loss: 0.728313\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)] Loss: 0.738806\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)] Loss: 0.744152\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4672, Accuracy: 8300/10000, 83.0)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12800/60000 (21%)] Loss: 0.593567\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [25600/60000 (43%)] Loss: 0.406311\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [38400/60000 (64%)] Loss: 0.520820\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [51200/60000 (85%)] Loss: 0.577668\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4322, Accuracy: 8433/10000, 84.33)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12800/60000 (21%)] Loss: 0.462949\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [25600/60000 (43%)] Loss: 0.566604\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [38400/60000 (64%)] Loss: 0.485074\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [51200/60000 (85%)] Loss: 0.410375\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.4150, Accuracy: 8494/10000, 84.94)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [12800/60000 (21%)] Loss: 0.526268\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [25600/60000 (43%)] Loss: 0.484240\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [38400/60000 (64%)] Loss: 0.545515\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [51200/60000 (85%)] Loss: 0.533635\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3920, Accuracy: 8549/10000, 85.49)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [12800/60000 (21%)] Loss: 0.567012\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [25600/60000 (43%)] Loss: 0.457122\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [38400/60000 (64%)] Loss: 0.547794\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [51200/60000 (85%)] Loss: 0.460627\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3805, Accuracy: 8602/10000, 86.02)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [12800/60000 (21%)] Loss: 0.458557\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [25600/60000 (43%)] Loss: 0.498100\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [38400/60000 (64%)] Loss: 0.528650\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [51200/60000 (85%)] Loss: 0.426028\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3689, Accuracy: 8615/10000, 86.15)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [12800/60000 (21%)] Loss: 0.449946\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [25600/60000 (43%)] Loss: 0.403428\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [38400/60000 (64%)] Loss: 0.446887\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [51200/60000 (85%)] Loss: 0.462430\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3637, Accuracy: 8666/10000, 86.66)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [12800/60000 (21%)] Loss: 0.404510\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [25600/60000 (43%)] Loss: 0.488245\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [38400/60000 (64%)] Loss: 0.650988\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [51200/60000 (85%)] Loss: 0.366090\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3527, Accuracy: 8689/10000, 86.89)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [12800/60000 (21%)] Loss: 0.484360\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [25600/60000 (43%)] Loss: 0.505227\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [38400/60000 (64%)] Loss: 0.498896\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [51200/60000 (85%)] Loss: 0.408989\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3494, Accuracy: 8708/10000, 87.08)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [12800/60000 (21%)] Loss: 0.412699\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [25600/60000 (43%)] Loss: 0.395737\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [38400/60000 (64%)] Loss: 0.438249\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [51200/60000 (85%)] Loss: 0.444148\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3422, Accuracy: 8729/10000, 87.29)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [12800/60000 (21%)] Loss: 0.411897\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [25600/60000 (43%)] Loss: 0.395662\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [38400/60000 (64%)] Loss: 0.325675\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [51200/60000 (85%)] Loss: 0.422936\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3408, Accuracy: 8723/10000, 87.23)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [12800/60000 (21%)] Loss: 0.328410\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [25600/60000 (43%)] Loss: 0.502289\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [38400/60000 (64%)] Loss: 0.484450\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [51200/60000 (85%)] Loss: 0.358022\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3430, Accuracy: 8779/10000, 87.79)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [12800/60000 (21%)] Loss: 0.448652\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [25600/60000 (43%)] Loss: 0.428358\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [38400/60000 (64%)] Loss: 0.507355\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [51200/60000 (85%)] Loss: 0.390873\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3322, Accuracy: 8787/10000, 87.87)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [12800/60000 (21%)] Loss: 0.357287\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [25600/60000 (43%)] Loss: 0.528082\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [38400/60000 (64%)] Loss: 0.327045\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [51200/60000 (85%)] Loss: 0.414922\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3331, Accuracy: 8786/10000, 87.86)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [12800/60000 (21%)] Loss: 0.554900\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [25600/60000 (43%)] Loss: 0.360345\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [38400/60000 (64%)] Loss: 0.330976\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [51200/60000 (85%)] Loss: 0.324512\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3307, Accuracy: 8786/10000, 87.86)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [12800/60000 (21%)] Loss: 0.425469\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [25600/60000 (43%)] Loss: 0.463365\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [38400/60000 (64%)] Loss: 0.280926\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [51200/60000 (85%)] Loss: 0.409863\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3228, Accuracy: 8797/10000, 87.97)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [12800/60000 (21%)] Loss: 0.419942\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [25600/60000 (43%)] Loss: 0.313066\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [38400/60000 (64%)] Loss: 0.464564\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [51200/60000 (85%)] Loss: 0.402573\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3203, Accuracy: 8827/10000, 88.27)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [12800/60000 (21%)] Loss: 0.328357\u001b[0m\n",
      "LossNotDecreasing: IssuesFound\n",
      "\u001b[34mTrain Epoch: 19 [25600/60000 (43%)] Loss: 0.432013\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [38400/60000 (64%)] Loss: 0.412822\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [51200/60000 (85%)] Loss: 0.374081\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3293, Accuracy: 8780/10000, 87.8)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [12800/60000 (21%)] Loss: 0.415452\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [25600/60000 (43%)] Loss: 0.351553\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [38400/60000 (64%)] Loss: 0.377977\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [51200/60000 (85%)] Loss: 0.485750\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3206, Accuracy: 8825/10000, 88.25)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [12800/60000 (21%)] Loss: 0.379266\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [25600/60000 (43%)] Loss: 0.272404\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [38400/60000 (64%)] Loss: 0.377064\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [51200/60000 (85%)] Loss: 0.345681\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3211, Accuracy: 8810/10000, 88.1)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [12800/60000 (21%)] Loss: 0.449724\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [25600/60000 (43%)] Loss: 0.385517\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [38400/60000 (64%)] Loss: 0.364489\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [51200/60000 (85%)] Loss: 0.351819\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3171, Accuracy: 8774/10000, 87.74)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [12800/60000 (21%)] Loss: 0.350387\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [25600/60000 (43%)] Loss: 0.300241\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [38400/60000 (64%)] Loss: 0.474715\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [51200/60000 (85%)] Loss: 0.292143\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3135, Accuracy: 8851/10000, 88.51)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [12800/60000 (21%)] Loss: 0.332284\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [25600/60000 (43%)] Loss: 0.494654\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [38400/60000 (64%)] Loss: 0.376274\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [51200/60000 (85%)] Loss: 0.426145\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3195, Accuracy: 8825/10000, 88.25)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [12800/60000 (21%)] Loss: 0.396635\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [25600/60000 (43%)] Loss: 0.349874\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [38400/60000 (64%)] Loss: 0.377974\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [51200/60000 (85%)] Loss: 0.383057\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3189, Accuracy: 8861/10000, 88.61)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [12800/60000 (21%)] Loss: 0.414222\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [25600/60000 (43%)] Loss: 0.540644\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [38400/60000 (64%)] Loss: 0.411902\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [51200/60000 (85%)] Loss: 0.428235\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3110, Accuracy: 8847/10000, 88.47)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [12800/60000 (21%)] Loss: 0.374094\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [25600/60000 (43%)] Loss: 0.343347\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [38400/60000 (64%)] Loss: 0.394932\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [51200/60000 (85%)] Loss: 0.212366\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3109, Accuracy: 8874/10000, 88.74)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [12800/60000 (21%)] Loss: 0.350478\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [25600/60000 (43%)] Loss: 0.378527\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [38400/60000 (64%)] Loss: 0.385569\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [51200/60000 (85%)] Loss: 0.431735\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3115, Accuracy: 8838/10000, 88.38)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [12800/60000 (21%)] Loss: 0.395454\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [25600/60000 (43%)] Loss: 0.461225\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [38400/60000 (64%)] Loss: 0.519479\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [51200/60000 (85%)] Loss: 0.739183\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3099, Accuracy: 8849/10000, 88.49)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [12800/60000 (21%)] Loss: 0.365630\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [25600/60000 (43%)] Loss: 0.454664\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [38400/60000 (64%)] Loss: 0.240816\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [51200/60000 (85%)] Loss: 0.282026\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3141, Accuracy: 8833/10000, 88.33)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [12800/60000 (21%)] Loss: 0.506772\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [25600/60000 (43%)] Loss: 0.350269\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [38400/60000 (64%)] Loss: 0.399217\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [51200/60000 (85%)] Loss: 0.352540\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3064, Accuracy: 8853/10000, 88.53)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [12800/60000 (21%)] Loss: 0.397212\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [25600/60000 (43%)] Loss: 0.374843\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [38400/60000 (64%)] Loss: 0.360218\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [51200/60000 (85%)] Loss: 0.344361\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3032, Accuracy: 8876/10000, 88.76)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [12800/60000 (21%)] Loss: 0.416560\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [25600/60000 (43%)] Loss: 0.353218\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [38400/60000 (64%)] Loss: 0.219566\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [51200/60000 (85%)] Loss: 0.284698\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3056, Accuracy: 8889/10000, 88.89)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [12800/60000 (21%)] Loss: 0.336986\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [25600/60000 (43%)] Loss: 0.460185\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [38400/60000 (64%)] Loss: 0.355344\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [51200/60000 (85%)] Loss: 0.298672\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3074, Accuracy: 8867/10000, 88.67)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [12800/60000 (21%)] Loss: 0.401673\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [25600/60000 (43%)] Loss: 0.260007\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [38400/60000 (64%)] Loss: 0.416208\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [51200/60000 (85%)] Loss: 0.359204\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3051, Accuracy: 8896/10000, 88.96)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [12800/60000 (21%)] Loss: 0.348177\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [25600/60000 (43%)] Loss: 0.330934\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [38400/60000 (64%)] Loss: 0.414105\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [51200/60000 (85%)] Loss: 0.371991\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3019, Accuracy: 8880/10000, 88.8)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [12800/60000 (21%)] Loss: 0.371524\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [25600/60000 (43%)] Loss: 0.376735\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [38400/60000 (64%)] Loss: 0.385543\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [51200/60000 (85%)] Loss: 0.307617\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3025, Accuracy: 8855/10000, 88.55)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [12800/60000 (21%)] Loss: 0.348066\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [25600/60000 (43%)] Loss: 0.384794\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [38400/60000 (64%)] Loss: 0.398589\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [51200/60000 (85%)] Loss: 0.420599\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2994, Accuracy: 8899/10000, 88.99)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [12800/60000 (21%)] Loss: 0.261723\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [25600/60000 (43%)] Loss: 0.401518\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [38400/60000 (64%)] Loss: 0.419929\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [51200/60000 (85%)] Loss: 0.451632\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3079, Accuracy: 8853/10000, 88.53)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [12800/60000 (21%)] Loss: 0.442474\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [25600/60000 (43%)] Loss: 0.374042\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [38400/60000 (64%)] Loss: 0.377711\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [51200/60000 (85%)] Loss: 0.495555\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3040, Accuracy: 8854/10000, 88.54)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [12800/60000 (21%)] Loss: 0.507903\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [25600/60000 (43%)] Loss: 0.490971\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [38400/60000 (64%)] Loss: 0.426350\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [51200/60000 (85%)] Loss: 0.345596\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3011, Accuracy: 8884/10000, 88.84)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [12800/60000 (21%)] Loss: 0.391089\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [25600/60000 (43%)] Loss: 0.360643\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [38400/60000 (64%)] Loss: 0.329237\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [51200/60000 (85%)] Loss: 0.480324\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2992, Accuracy: 8904/10000, 89.04)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [12800/60000 (21%)] Loss: 0.305467\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [25600/60000 (43%)] Loss: 0.410970\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [38400/60000 (64%)] Loss: 0.373812\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [51200/60000 (85%)] Loss: 0.252375\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3056, Accuracy: 8859/10000, 88.59)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [12800/60000 (21%)] Loss: 0.332624\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [25600/60000 (43%)] Loss: 0.286648\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [38400/60000 (64%)] Loss: 0.339845\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [51200/60000 (85%)] Loss: 0.451387\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3043, Accuracy: 8875/10000, 88.75)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [12800/60000 (21%)] Loss: 0.422617\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [25600/60000 (43%)] Loss: 0.401985\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [38400/60000 (64%)] Loss: 0.505562\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [51200/60000 (85%)] Loss: 0.344469\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3042, Accuracy: 8884/10000, 88.84)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [12800/60000 (21%)] Loss: 0.420595\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [25600/60000 (43%)] Loss: 0.405001\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [38400/60000 (64%)] Loss: 0.423034\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [51200/60000 (85%)] Loss: 0.318113\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3016, Accuracy: 8893/10000, 88.93)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [12800/60000 (21%)] Loss: 0.442455\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [25600/60000 (43%)] Loss: 0.509587\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [38400/60000 (64%)] Loss: 0.359873\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [51200/60000 (85%)] Loss: 0.285887\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3015, Accuracy: 8896/10000, 88.96)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [12800/60000 (21%)] Loss: 0.356636\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [25600/60000 (43%)] Loss: 0.307030\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [38400/60000 (64%)] Loss: 0.428909\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [51200/60000 (85%)] Loss: 0.302872\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2981, Accuracy: 8914/10000, 89.14)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [12800/60000 (21%)] Loss: 0.368047\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [25600/60000 (43%)] Loss: 0.373855\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [38400/60000 (64%)] Loss: 0.405347\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [51200/60000 (85%)] Loss: 0.248748\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2940, Accuracy: 8914/10000, 89.14)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [12800/60000 (21%)] Loss: 0.362550\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [25600/60000 (43%)] Loss: 0.353432\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [38400/60000 (64%)] Loss: 0.340345\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [51200/60000 (85%)] Loss: 0.381175\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3007, Accuracy: 8903/10000, 89.03)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [12800/60000 (21%)] Loss: 0.479469\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [25600/60000 (43%)] Loss: 0.439617\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [38400/60000 (64%)] Loss: 0.453364\u001b[0m\n",
      "\u001b[34mTrain Epoch: 51 [51200/60000 (85%)] Loss: 0.239260\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2963, Accuracy: 8908/10000, 89.08)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [12800/60000 (21%)] Loss: 0.307850\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [25600/60000 (43%)] Loss: 0.370997\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [38400/60000 (64%)] Loss: 0.308411\u001b[0m\n",
      "\u001b[34mTrain Epoch: 52 [51200/60000 (85%)] Loss: 0.337795\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2986, Accuracy: 8892/10000, 88.92)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [12800/60000 (21%)] Loss: 0.266452\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [25600/60000 (43%)] Loss: 0.393776\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [38400/60000 (64%)] Loss: 0.471699\u001b[0m\n",
      "\u001b[34mTrain Epoch: 53 [51200/60000 (85%)] Loss: 0.411884\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3001, Accuracy: 8877/10000, 88.77)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [12800/60000 (21%)] Loss: 0.289681\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [25600/60000 (43%)] Loss: 0.252537\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [38400/60000 (64%)] Loss: 0.339356\u001b[0m\n",
      "\u001b[34mTrain Epoch: 54 [51200/60000 (85%)] Loss: 0.327685\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2969, Accuracy: 8888/10000, 88.88)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [12800/60000 (21%)] Loss: 0.287986\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [25600/60000 (43%)] Loss: 0.461079\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [38400/60000 (64%)] Loss: 0.462064\u001b[0m\n",
      "\u001b[34mTrain Epoch: 55 [51200/60000 (85%)] Loss: 0.430224\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2970, Accuracy: 8895/10000, 88.95)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [12800/60000 (21%)] Loss: 0.253739\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [25600/60000 (43%)] Loss: 0.252470\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [38400/60000 (64%)] Loss: 0.258986\u001b[0m\n",
      "\u001b[34mTrain Epoch: 56 [51200/60000 (85%)] Loss: 0.304927\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2965, Accuracy: 8891/10000, 88.91)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [12800/60000 (21%)] Loss: 0.430266\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [25600/60000 (43%)] Loss: 0.449774\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [38400/60000 (64%)] Loss: 0.295538\u001b[0m\n",
      "\u001b[34mTrain Epoch: 57 [51200/60000 (85%)] Loss: 0.403913\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2947, Accuracy: 8908/10000, 89.08)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [12800/60000 (21%)] Loss: 0.256482\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [25600/60000 (43%)] Loss: 0.368793\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [38400/60000 (64%)] Loss: 0.515854\u001b[0m\n",
      "\u001b[34mTrain Epoch: 58 [51200/60000 (85%)] Loss: 0.373380\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2936, Accuracy: 8904/10000, 89.04)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [12800/60000 (21%)] Loss: 0.341670\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [25600/60000 (43%)] Loss: 0.325627\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [38400/60000 (64%)] Loss: 0.329193\u001b[0m\n",
      "\u001b[34mTrain Epoch: 59 [51200/60000 (85%)] Loss: 0.289901\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2938, Accuracy: 8904/10000, 89.04)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [12800/60000 (21%)] Loss: 0.361560\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [25600/60000 (43%)] Loss: 0.374250\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [38400/60000 (64%)] Loss: 0.354810\u001b[0m\n",
      "\u001b[34mTrain Epoch: 60 [51200/60000 (85%)] Loss: 0.271961\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2984, Accuracy: 8920/10000, 89.2)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [12800/60000 (21%)] Loss: 0.364741\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [25600/60000 (43%)] Loss: 0.456524\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [38400/60000 (64%)] Loss: 0.347223\u001b[0m\n",
      "\u001b[34mTrain Epoch: 61 [51200/60000 (85%)] Loss: 0.341344\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2950, Accuracy: 8915/10000, 89.15)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [12800/60000 (21%)] Loss: 0.311264\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [25600/60000 (43%)] Loss: 0.617320\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [38400/60000 (64%)] Loss: 0.392554\u001b[0m\n",
      "\u001b[34mTrain Epoch: 62 [51200/60000 (85%)] Loss: 0.449073\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2946, Accuracy: 8937/10000, 89.37)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [12800/60000 (21%)] Loss: 0.578236\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [25600/60000 (43%)] Loss: 0.355247\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [38400/60000 (64%)] Loss: 0.257275\u001b[0m\n",
      "\u001b[34mTrain Epoch: 63 [51200/60000 (85%)] Loss: 0.322628\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2938, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [12800/60000 (21%)] Loss: 0.254509\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [25600/60000 (43%)] Loss: 0.362961\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [38400/60000 (64%)] Loss: 0.322869\u001b[0m\n",
      "\u001b[34mTrain Epoch: 64 [51200/60000 (85%)] Loss: 0.346103\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2948, Accuracy: 8918/10000, 89.18)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [12800/60000 (21%)] Loss: 0.308356\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [25600/60000 (43%)] Loss: 0.503055\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [38400/60000 (64%)] Loss: 0.335929\u001b[0m\n",
      "\u001b[34mTrain Epoch: 65 [51200/60000 (85%)] Loss: 0.279766\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2943, Accuracy: 8926/10000, 89.26)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [12800/60000 (21%)] Loss: 0.310296\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [25600/60000 (43%)] Loss: 0.349454\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [38400/60000 (64%)] Loss: 0.444520\u001b[0m\n",
      "\u001b[34mTrain Epoch: 66 [51200/60000 (85%)] Loss: 0.240954\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2924, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [12800/60000 (21%)] Loss: 0.469586\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [25600/60000 (43%)] Loss: 0.273475\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [38400/60000 (64%)] Loss: 0.256117\u001b[0m\n",
      "\u001b[34mTrain Epoch: 67 [51200/60000 (85%)] Loss: 0.354425\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2943, Accuracy: 8885/10000, 88.85)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [12800/60000 (21%)] Loss: 0.399046\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [25600/60000 (43%)] Loss: 0.287503\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [38400/60000 (64%)] Loss: 0.454066\u001b[0m\n",
      "\u001b[34mTrain Epoch: 68 [51200/60000 (85%)] Loss: 0.218936\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2968, Accuracy: 8926/10000, 89.26)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [12800/60000 (21%)] Loss: 0.363659\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [25600/60000 (43%)] Loss: 0.505572\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [38400/60000 (64%)] Loss: 0.353649\u001b[0m\n",
      "\u001b[34mTrain Epoch: 69 [51200/60000 (85%)] Loss: 0.286465\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2918, Accuracy: 8933/10000, 89.33)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [12800/60000 (21%)] Loss: 0.337610\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [25600/60000 (43%)] Loss: 0.366760\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [38400/60000 (64%)] Loss: 0.384299\u001b[0m\n",
      "\u001b[34mTrain Epoch: 70 [51200/60000 (85%)] Loss: 0.293448\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2922, Accuracy: 8911/10000, 89.11)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [12800/60000 (21%)] Loss: 0.285239\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [25600/60000 (43%)] Loss: 0.394368\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [38400/60000 (64%)] Loss: 0.346128\u001b[0m\n",
      "\u001b[34mTrain Epoch: 71 [51200/60000 (85%)] Loss: 0.400058\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3002, Accuracy: 8913/10000, 89.13)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [12800/60000 (21%)] Loss: 0.293868\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [25600/60000 (43%)] Loss: 0.407205\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [38400/60000 (64%)] Loss: 0.403528\u001b[0m\n",
      "\u001b[34mTrain Epoch: 72 [51200/60000 (85%)] Loss: 0.349785\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2930, Accuracy: 8925/10000, 89.25)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [12800/60000 (21%)] Loss: 0.300030\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [25600/60000 (43%)] Loss: 0.342314\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [38400/60000 (64%)] Loss: 0.387698\u001b[0m\n",
      "\u001b[34mTrain Epoch: 73 [51200/60000 (85%)] Loss: 0.404557\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2897, Accuracy: 8925/10000, 89.25)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [12800/60000 (21%)] Loss: 0.382757\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [25600/60000 (43%)] Loss: 0.329481\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [38400/60000 (64%)] Loss: 0.287810\u001b[0m\n",
      "\u001b[34mTrain Epoch: 74 [51200/60000 (85%)] Loss: 0.465718\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2956, Accuracy: 8905/10000, 89.05)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [12800/60000 (21%)] Loss: 0.332887\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [25600/60000 (43%)] Loss: 0.334465\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [38400/60000 (64%)] Loss: 0.525027\u001b[0m\n",
      "\u001b[34mTrain Epoch: 75 [51200/60000 (85%)] Loss: 0.389569\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2922, Accuracy: 8921/10000, 89.21)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [12800/60000 (21%)] Loss: 0.385011\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [25600/60000 (43%)] Loss: 0.345658\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [38400/60000 (64%)] Loss: 0.220821\u001b[0m\n",
      "\u001b[34mTrain Epoch: 76 [51200/60000 (85%)] Loss: 0.325413\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2897, Accuracy: 8922/10000, 89.22)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [12800/60000 (21%)] Loss: 0.422568\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [25600/60000 (43%)] Loss: 0.443173\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [38400/60000 (64%)] Loss: 0.372074\u001b[0m\n",
      "\u001b[34mTrain Epoch: 77 [51200/60000 (85%)] Loss: 0.369760\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2950, Accuracy: 8893/10000, 88.93)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [12800/60000 (21%)] Loss: 0.380856\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [25600/60000 (43%)] Loss: 0.437522\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [38400/60000 (64%)] Loss: 0.414514\u001b[0m\n",
      "\u001b[34mTrain Epoch: 78 [51200/60000 (85%)] Loss: 0.362339\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2942, Accuracy: 8909/10000, 89.09)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [12800/60000 (21%)] Loss: 0.336717\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [25600/60000 (43%)] Loss: 0.387197\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [38400/60000 (64%)] Loss: 0.309343\u001b[0m\n",
      "\u001b[34mTrain Epoch: 79 [51200/60000 (85%)] Loss: 0.385251\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.3023, Accuracy: 8888/10000, 88.88)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [12800/60000 (21%)] Loss: 0.481130\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [25600/60000 (43%)] Loss: 0.281604\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [38400/60000 (64%)] Loss: 0.319897\u001b[0m\n",
      "\u001b[34mTrain Epoch: 80 [51200/60000 (85%)] Loss: 0.382902\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2911, Accuracy: 8931/10000, 89.31)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [12800/60000 (21%)] Loss: 0.360859\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [25600/60000 (43%)] Loss: 0.367887\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [38400/60000 (64%)] Loss: 0.385954\u001b[0m\n",
      "\u001b[34mTrain Epoch: 81 [51200/60000 (85%)] Loss: 0.326182\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2913, Accuracy: 8921/10000, 89.21)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [12800/60000 (21%)] Loss: 0.403094\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [25600/60000 (43%)] Loss: 0.352049\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [38400/60000 (64%)] Loss: 0.335068\u001b[0m\n",
      "\u001b[34mTrain Epoch: 82 [51200/60000 (85%)] Loss: 0.323285\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2875, Accuracy: 8953/10000, 89.53)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [12800/60000 (21%)] Loss: 0.293779\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [25600/60000 (43%)] Loss: 0.337245\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [38400/60000 (64%)] Loss: 0.283721\u001b[0m\n",
      "\u001b[34mTrain Epoch: 83 [51200/60000 (85%)] Loss: 0.348331\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2949, Accuracy: 8916/10000, 89.16)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [12800/60000 (21%)] Loss: 0.438669\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [25600/60000 (43%)] Loss: 0.309452\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [38400/60000 (64%)] Loss: 0.399734\u001b[0m\n",
      "\u001b[34mTrain Epoch: 84 [51200/60000 (85%)] Loss: 0.290429\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2932, Accuracy: 8898/10000, 88.98)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [12800/60000 (21%)] Loss: 0.291697\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [25600/60000 (43%)] Loss: 0.269024\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [38400/60000 (64%)] Loss: 0.434426\u001b[0m\n",
      "\u001b[34mTrain Epoch: 85 [51200/60000 (85%)] Loss: 0.250350\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2880, Accuracy: 8943/10000, 89.43)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [12800/60000 (21%)] Loss: 0.392573\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [25600/60000 (43%)] Loss: 0.414181\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [38400/60000 (64%)] Loss: 0.421218\u001b[0m\n",
      "\u001b[34mTrain Epoch: 86 [51200/60000 (85%)] Loss: 0.320884\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2911, Accuracy: 8916/10000, 89.16)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [12800/60000 (21%)] Loss: 0.427020\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [25600/60000 (43%)] Loss: 0.276295\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [38400/60000 (64%)] Loss: 0.203625\u001b[0m\n",
      "\u001b[34mTrain Epoch: 87 [51200/60000 (85%)] Loss: 0.321268\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2944, Accuracy: 8929/10000, 89.29)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [12800/60000 (21%)] Loss: 0.250110\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [25600/60000 (43%)] Loss: 0.431817\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [38400/60000 (64%)] Loss: 0.411524\u001b[0m\n",
      "\u001b[34mTrain Epoch: 88 [51200/60000 (85%)] Loss: 0.286772\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2897, Accuracy: 8938/10000, 89.38)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [12800/60000 (21%)] Loss: 0.351494\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [25600/60000 (43%)] Loss: 0.291769\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [38400/60000 (64%)] Loss: 0.440283\u001b[0m\n",
      "\u001b[34mTrain Epoch: 89 [51200/60000 (85%)] Loss: 0.473217\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2899, Accuracy: 8946/10000, 89.46)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [12800/60000 (21%)] Loss: 0.411508\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [25600/60000 (43%)] Loss: 0.303058\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [38400/60000 (64%)] Loss: 0.652012\u001b[0m\n",
      "\u001b[34mTrain Epoch: 90 [51200/60000 (85%)] Loss: 0.403120\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2891, Accuracy: 8961/10000, 89.61)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [12800/60000 (21%)] Loss: 0.306777\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [25600/60000 (43%)] Loss: 0.326502\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [38400/60000 (64%)] Loss: 0.480544\u001b[0m\n",
      "\u001b[34mTrain Epoch: 91 [51200/60000 (85%)] Loss: 0.318608\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2887, Accuracy: 8948/10000, 89.48)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [12800/60000 (21%)] Loss: 0.361663\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [25600/60000 (43%)] Loss: 0.372615\u001b[0m\n",
      "\u001b[34mTrain Epoch: 92 [38400/60000 (64%)] Loss: 0.332478\u001b[0m\n",
      "LowGPUUtilization: IssuesFound\n",
      "ProfilerReport: InProgress\n",
      "\u001b[34mTrain Epoch: 92 [51200/60000 (85%)] Loss: 0.478083\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2921, Accuracy: 8941/10000, 89.41)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [12800/60000 (21%)] Loss: 0.351473\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [25600/60000 (43%)] Loss: 0.463441\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [38400/60000 (64%)] Loss: 0.249222\u001b[0m\n",
      "\u001b[34mTrain Epoch: 93 [51200/60000 (85%)] Loss: 0.319171\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2877, Accuracy: 8940/10000, 89.4)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [12800/60000 (21%)] Loss: 0.329673\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [25600/60000 (43%)] Loss: 0.405818\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [38400/60000 (64%)] Loss: 0.226946\u001b[0m\n",
      "\u001b[34mTrain Epoch: 94 [51200/60000 (85%)] Loss: 0.307445\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2830, Accuracy: 8952/10000, 89.52)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [12800/60000 (21%)] Loss: 0.402693\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [25600/60000 (43%)] Loss: 0.325117\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [38400/60000 (64%)] Loss: 0.369948\u001b[0m\n",
      "\u001b[34mTrain Epoch: 95 [51200/60000 (85%)] Loss: 0.337758\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2865, Accuracy: 8941/10000, 89.41)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [12800/60000 (21%)] Loss: 0.385209\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [25600/60000 (43%)] Loss: 0.478564\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [38400/60000 (64%)] Loss: 0.253567\u001b[0m\n",
      "\u001b[34mTrain Epoch: 96 [51200/60000 (85%)] Loss: 0.369775\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2867, Accuracy: 8963/10000, 89.63)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [12800/60000 (21%)] Loss: 0.266360\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [25600/60000 (43%)] Loss: 0.285985\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [38400/60000 (64%)] Loss: 0.404045\u001b[0m\n",
      "\u001b[34mTrain Epoch: 97 [51200/60000 (85%)] Loss: 0.469731\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2891, Accuracy: 8932/10000, 89.32)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [12800/60000 (21%)] Loss: 0.404628\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [25600/60000 (43%)] Loss: 0.273948\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [38400/60000 (64%)] Loss: 0.422566\u001b[0m\n",
      "\u001b[34mTrain Epoch: 98 [51200/60000 (85%)] Loss: 0.407212\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.2884, Accuracy: 8918/10000, 89.18)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 99 [12800/60000 (21%)] Loss: 0.225978\u001b[0m\n",
      "\u001b[34mTrain Epoch: 99 [25600/60000 (43%)] Loss: 0.461605\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "job_name=estimator.latest_training_job.name\n",
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668fa56b",
   "metadata": {},
   "source": [
    "### Download profiler report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddd8c0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_output_path = estimator.output_path + '/' + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "rule_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc4e3027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-09 13:55:22     389321 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-report.html\n",
      "2021-12-09 13:55:21     239418 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-report.ipynb\n",
      "2021-12-09 13:55:17        191 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/BatchSize.json\n",
      "2021-12-09 13:55:17      10527 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "2021-12-09 13:55:17       1927 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/Dataloader.json\n",
      "2021-12-09 13:55:17        129 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "2021-12-09 13:55:17      10621 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json\n",
      "2021-12-09 13:55:17        307 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json\n",
      "2021-12-09 13:55:17        153 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "2021-12-09 13:55:17        233 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "2021-12-09 13:55:17       1266 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "2021-12-09 13:55:17        603 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "2021-12-09 13:55:17       2434 tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {rule_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff846ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./profiler', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4178621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json to profiler/ProfilerReport/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/Dataloader.json to profiler/ProfilerReport/profiler-output/profiler-reports/Dataloader.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json to profiler/ProfilerReport/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-report.html to profiler/ProfilerReport/profiler-output/profiler-report.html\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json to profiler/ProfilerReport/profiler-output/profiler-reports/IOBottleneck.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json to profiler/ProfilerReport/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/BatchSize.json to profiler/ProfilerReport/profiler-output/profiler-reports/BatchSize.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json to profiler/ProfilerReport/profiler-output/profiler-reports/LoadBalancing.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json to profiler/ProfilerReport/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json to profiler/ProfilerReport/profiler-output/profiler-reports/StepOutlier.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json to profiler/ProfilerReport/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-report.ipynb to profiler/ProfilerReport/profiler-output/profiler-report.ipynb\n",
      "download: s3://sagemaker-ap-northeast-2-889750940888/tensorboard_pytorch_fashion_mnist/output/pytorch-tensorboard-2021-12-09-13-46-49-120/rule-output/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json to profiler/ProfilerReport/profiler-output/profiler-reports/MaxInitializationTime.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp {rule_output_path} ./profiler --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753694f",
   "metadata": {},
   "source": [
    "# Screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8118f0",
   "metadata": {},
   "source": [
    "![tensorboard](image/01.tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c445bb",
   "metadata": {},
   "source": [
    "![SM-experiments](image/02.SM-experiments.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6bec1",
   "metadata": {},
   "source": [
    "![SM-debugger](image/03.SM-debugger.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f7c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
