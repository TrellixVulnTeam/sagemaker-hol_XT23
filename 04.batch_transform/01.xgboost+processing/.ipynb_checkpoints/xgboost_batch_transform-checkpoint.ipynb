{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067eb26d",
   "metadata": {},
   "source": [
    "# XGBoost 학습 후 Batch Transform w/ SM Processing\n",
    "- Training: Managed training\n",
    "- Processing: Local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04214cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install_needed = True  # should only be True once\n",
    "install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db425e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U 'sagemaker[local]'\n",
    "    !{sys.executable} -m pip install -U sagemaker-experiments # SageMaker Experiments SDK \n",
    "    !{sys.executable} -m pip install -U sagemaker             # SageMaker Python SDK\n",
    "    !{sys.executable} -m pip install -U boto3\n",
    "    \n",
    "    IPython.Application.instance().kernel.do_shutdown(True)\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01914c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "import time\n",
    "from time import gmtime, strftime "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22493fb5",
   "metadata": {},
   "source": [
    "## Prepare & Uplad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dc1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70867044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names\n",
    "data['PRICE'] = boston.target\n",
    "\n",
    "data.to_csv('./data/boston.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67eee4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::889750940888:role/service-role/AmazonSageMaker-ExecutionRole-20210830T114616'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'batch-transform/xgboost-byos'\n",
    "output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4795a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = session.upload_data('./data', key_prefix=f'{prefix}/data')\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4595cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:10:24      41085 batch-transform/xgboost-byos/data/.ipynb_checkpoints/boston-checkpoint.csv\n",
      "2022-01-05 00:10:24      39170 batch-transform/xgboost-byos/data/boston.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {input_data} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5409fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/train.py\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Hyperparameters are described here.\n",
    "parser.add_argument(\"--max_depth\", type=int, default=5)\n",
    "parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "parser.add_argument(\"--gamma\", type=int, default=4)\n",
    "parser.add_argument(\"--min_child_weight\", type=int, default=6)\n",
    "parser.add_argument(\"--subsample\", type=float, default=0.7)\n",
    "parser.add_argument(\"--verbosity\", type=int, default=2)\n",
    "parser.add_argument(\"--objective\", type=str, default='reg:squarederror')\n",
    "parser.add_argument(\"--num_round\", type=int, default=50)\n",
    "parser.add_argument(\"--tree_method\", type=str, default=\"auto\")\n",
    "parser.add_argument(\"--predictor\", type=str, default=\"auto\")\n",
    "\n",
    "# SageMaker specific arguments. Defaults are set in the environment variables.\n",
    "parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "# parser.add_argument('--validation', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "data = pd.read_csv(f'{args.train}/boston.csv')\n",
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "train_hp = {\n",
    "    \"max_depth\": args.max_depth,\n",
    "    \"eta\": args.eta,\n",
    "    \"gamma\": args.gamma,\n",
    "    \"min_child_weight\": args.min_child_weight,\n",
    "    \"subsample\": args.subsample,\n",
    "    \"verbosity\": args.verbosity,\n",
    "    \"objective\": args.objective,\n",
    "    \"tree_method\": args.tree_method,\n",
    "    \"predictor\": args.predictor,\n",
    "}\n",
    "\n",
    "model_xgb = xgb.train(params=train_hp, \n",
    "                      dtrain=train,\n",
    "                      evals=[(train, \"train\"), (test, \"validation\")], \n",
    "                      num_boost_round=100,\n",
    "                      early_stopping_rounds=20)\n",
    "\n",
    "preds = model_xgb.predict(test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "model_xgb.save_model(f'{args.model_dir}/model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1895b44",
   "metadata": {},
   "source": [
    "## Local mode training\n",
    "- Reference: https://github.com/aws-samples/amazon-sagemaker-local-mode/tree/main/xgboost_script_mode_local_training_and_serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18c99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_local = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a8bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-regression-2022-01-05-00-10-24\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "use_spot_instances = False\n",
    "job_name = \"DEMO-xgboost-regression-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "xgb_script_mode_estimator_local = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir='source_dir',\n",
    "    hyperparameters=hyperparameters_local,\n",
    "    # Case1) SageMaker Notebook => role=sagemaker.get_execution_role()\n",
    "    # Case2) Non SageMaker Notebook (e.g., My Laptop): role='arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001' & local credentials\n",
    "    role=role,\n",
    "#     role='arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001',\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version='1.3-1',\n",
    "    output_path=output_path,\n",
    "    base_job_name='xgboost-batch-transform',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652c3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_local = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13010188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 10gka0f4de-algo-1-llgrt ... \n",
      "Creating 10gka0f4de-algo-1-llgrt ... done\n",
      "Attaching to 10gka0f4de-algo-1-llgrt\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05 00:10:26.907 bd132f9a1486:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:26:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:26:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:26:INFO] Invoking user training script.\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:27:INFO] Module train does not provide a setup.py. \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Generating setup.py\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:27:INFO] Generating setup.cfg\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:27:INFO] Generating MANIFEST.in\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:27:INFO] Installing module with the following command:\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \u001b[?25hBuilding wheels for collected packages: train\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=7510 sha256=a302a74c81a1e303d5ef1ff43f42807b20b858c01e0bb784adf15c368942cfdf\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-x7e9q3o2/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Successfully built train\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Installing collected packages: train\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m You should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:28:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2022-01-05:00:10:28:INFO] Invoking user script\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Training Env:\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m {\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     },\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"current_host\": \"algo-1-llgrt\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"algo-1-llgrt\"\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     ],\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"max_depth\": \"5\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"eta\": \"0.2\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"gamma\": \"4\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"min_child_weight\": \"6\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"subsample\": \"0.7\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"objective\": \"reg:squarederror\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"num_round\": \"50\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"verbosity\": \"2\"\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     },\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"train\": {\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         }\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     },\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"job_name\": \"xgboost-batch-transform-2022-01-05-00-10-24-276\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"master_hostname\": \"algo-1-llgrt\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2022-01-05-00-10-24-276/source/sourcedir.tar.gz\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"current_host\": \"algo-1-llgrt\",\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m             \"algo-1-llgrt\"\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m         ]\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     },\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m }\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Environment variables:\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HOSTS=[\"algo-1-llgrt\"]\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"}\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-llgrt\",\"hosts\":[\"algo-1-llgrt\"]}\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_CURRENT_HOST=algo-1-llgrt\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2022-01-05-00-10-24-276/source/sourcedir.tar.gz\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-llgrt\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-llgrt\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgboost-batch-transform-2022-01-05-00-10-24-276\",\"log_level\":20,\"master_hostname\":\"algo-1-llgrt\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2022-01-05-00-10-24-276/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-llgrt\",\"hosts\":[\"algo-1-llgrt\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\",\"--verbosity\",\"2\"]\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_MAX_DEPTH=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_ETA=0.2\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_GAMMA=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_MIN_CHILD_WEIGHT=6\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_SUBSAMPLE=0.7\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_OBJECTIVE=reg:squarederror\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_NUM_ROUND=50\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m SM_HP_VERBOSITY=2\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m /miniconda3/bin/python3 -m train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:squarederror --subsample 0.7 --verbosity 2\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m \n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [0]\ttrain-rmse:19.24118\tvalidation-rmse:19.95601\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [1]\ttrain-rmse:15.75215\tvalidation-rmse:16.38510\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [2]\ttrain-rmse:12.91363\tvalidation-rmse:13.52608\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [3]\ttrain-rmse:10.66743\tvalidation-rmse:11.28941\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [4]\ttrain-rmse:8.78830\tvalidation-rmse:9.52816\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [5]\ttrain-rmse:7.33972\tvalidation-rmse:8.18952\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [6]\ttrain-rmse:6.14948\tvalidation-rmse:7.03950\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [7]\ttrain-rmse:5.27264\tvalidation-rmse:6.26622\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [8]\ttrain-rmse:4.52930\tvalidation-rmse:5.66625\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [9]\ttrain-rmse:3.95899\tvalidation-rmse:5.27399\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [10]\ttrain-rmse:3.49374\tvalidation-rmse:4.97541\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [11]\ttrain-rmse:3.13209\tvalidation-rmse:4.75218\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [12]\ttrain-rmse:2.83112\tvalidation-rmse:4.58555\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [13]\ttrain-rmse:2.62437\tvalidation-rmse:4.48671\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [14]\ttrain-rmse:2.46680\tvalidation-rmse:4.42469\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [15]\ttrain-rmse:2.36915\tvalidation-rmse:4.38059\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [16]\ttrain-rmse:2.26623\tvalidation-rmse:4.34073\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [17]\ttrain-rmse:2.18759\tvalidation-rmse:4.34964\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [18]\ttrain-rmse:2.10211\tvalidation-rmse:4.34712\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [19]\ttrain-rmse:2.05931\tvalidation-rmse:4.32084\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [20]\ttrain-rmse:2.01141\tvalidation-rmse:4.35449\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [21]\ttrain-rmse:1.97301\tvalidation-rmse:4.31907\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [22]\ttrain-rmse:1.91663\tvalidation-rmse:4.28586\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [23]\ttrain-rmse:1.87038\tvalidation-rmse:4.30955\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [24]\ttrain-rmse:1.82032\tvalidation-rmse:4.28163\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [25]\ttrain-rmse:1.80504\tvalidation-rmse:4.28857\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [26]\ttrain-rmse:1.76987\tvalidation-rmse:4.28809\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [27]\ttrain-rmse:1.73823\tvalidation-rmse:4.25169\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [28]\ttrain-rmse:1.71606\tvalidation-rmse:4.23968\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [29]\ttrain-rmse:1.67330\tvalidation-rmse:4.24842\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [30]\ttrain-rmse:1.62559\tvalidation-rmse:4.26586\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [31]\ttrain-rmse:1.59760\tvalidation-rmse:4.26000\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [32]\ttrain-rmse:1.55152\tvalidation-rmse:4.26473\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [33]\ttrain-rmse:1.50853\tvalidation-rmse:4.27072\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [34]\ttrain-rmse:1.48552\tvalidation-rmse:4.25470\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [35]\ttrain-rmse:1.46635\tvalidation-rmse:4.27687\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [36]\ttrain-rmse:1.44115\tvalidation-rmse:4.28142\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [37]\ttrain-rmse:1.38991\tvalidation-rmse:4.27546\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [38]\ttrain-rmse:1.36646\tvalidation-rmse:4.26779\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [39]\ttrain-rmse:1.35044\tvalidation-rmse:4.24015\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [40]\ttrain-rmse:1.33978\tvalidation-rmse:4.23646\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [41]\ttrain-rmse:1.31414\tvalidation-rmse:4.20633\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 14 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [42]\ttrain-rmse:1.29130\tvalidation-rmse:4.21417\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [43]\ttrain-rmse:1.27091\tvalidation-rmse:4.21721\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 22 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [44]\ttrain-rmse:1.24985\tvalidation-rmse:4.21544\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [45]\ttrain-rmse:1.23660\tvalidation-rmse:4.19613\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [46]\ttrain-rmse:1.22349\tvalidation-rmse:4.18851\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [47]\ttrain-rmse:1.19807\tvalidation-rmse:4.17394\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [48]\ttrain-rmse:1.18812\tvalidation-rmse:4.17702\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [49]\ttrain-rmse:1.17141\tvalidation-rmse:4.17989\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [50]\ttrain-rmse:1.15652\tvalidation-rmse:4.19870\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [51]\ttrain-rmse:1.13550\tvalidation-rmse:4.19223\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [52]\ttrain-rmse:1.12363\tvalidation-rmse:4.20107\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [53]\ttrain-rmse:1.11300\tvalidation-rmse:4.20329\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 10 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [54]\ttrain-rmse:1.10449\tvalidation-rmse:4.21082\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [55]\ttrain-rmse:1.09181\tvalidation-rmse:4.21811\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [56]\ttrain-rmse:1.06666\tvalidation-rmse:4.21898\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 4 extra nodes, 20 pruned nodes, max_depth=2\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [57]\ttrain-rmse:1.06525\tvalidation-rmse:4.22320\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [58]\ttrain-rmse:1.04762\tvalidation-rmse:4.18983\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 6 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [59]\ttrain-rmse:1.04244\tvalidation-rmse:4.18913\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 16 pruned nodes, max_depth=3\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [60]\ttrain-rmse:1.04076\tvalidation-rmse:4.17856\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [61]\ttrain-rmse:1.02975\tvalidation-rmse:4.15790\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [62]\ttrain-rmse:1.02307\tvalidation-rmse:4.17094\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [63]\ttrain-rmse:1.01656\tvalidation-rmse:4.19076\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 16 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [64]\ttrain-rmse:1.00606\tvalidation-rmse:4.19195\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [65]\ttrain-rmse:0.99547\tvalidation-rmse:4.18538\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 14 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [66]\ttrain-rmse:0.98517\tvalidation-rmse:4.18613\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 20 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [67]\ttrain-rmse:0.97999\tvalidation-rmse:4.18590\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 16 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [68]\ttrain-rmse:0.97276\tvalidation-rmse:4.18527\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [69]\ttrain-rmse:0.96251\tvalidation-rmse:4.18064\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [70]\ttrain-rmse:0.95313\tvalidation-rmse:4.19239\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 24 pruned nodes, max_depth=3\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [71]\ttrain-rmse:0.94996\tvalidation-rmse:4.18740\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 10 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [72]\ttrain-rmse:0.94329\tvalidation-rmse:4.18906\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [73]\ttrain-rmse:0.93778\tvalidation-rmse:4.18639\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [74]\ttrain-rmse:0.93375\tvalidation-rmse:4.18236\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 18 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [75]\ttrain-rmse:0.92501\tvalidation-rmse:4.18866\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [76]\ttrain-rmse:0.92514\tvalidation-rmse:4.18766\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [77]\ttrain-rmse:0.91727\tvalidation-rmse:4.18391\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [78]\ttrain-rmse:0.91137\tvalidation-rmse:4.19003\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [79]\ttrain-rmse:0.90431\tvalidation-rmse:4.18557\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 20 pruned nodes, max_depth=4\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [80]\ttrain-rmse:0.89655\tvalidation-rmse:4.18624\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [00:10:29] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 14 pruned nodes, max_depth=3\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m [81]\ttrain-rmse:0.89306\tvalidation-rmse:4.19691\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt |\u001b[0m RMSE: 4.196913\n",
      "\u001b[36m10gka0f4de-algo-1-llgrt exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "xgb_script_mode_estimator_local.fit(\n",
    "    {'train': 'file://{}'.format(input_data_local)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0be4a1",
   "metadata": {},
   "source": [
    "## Managed training w/ Spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e110efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_managed = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"500\",                    ### Increasing num_round\n",
    "    \"verbosity\": \"2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373cce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-regression-2022-01-05-00-10-29\n",
      "Checkpoint path: s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/checkpoints/DEMO-xgboost-regression-2022-01-05-00-10-29\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "use_spot_instances = True\n",
    "max_run = 60*60\n",
    "max_wait = 60*60\n",
    "\n",
    "job_name = \"DEMO-xgboost-regression-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "checkpoint_s3_uri = (\n",
    "    \"s3://{}/{}/checkpoints/{}\".format(bucket, prefix, job_name) if use_spot_instances else None\n",
    ")\n",
    "print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "\n",
    "xgb_script_mode_estimator_managed = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir='source_dir',\n",
    "    hyperparameters=hyperparameters_managed,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    framework_version='1.3-1',\n",
    "    output_path=output_path,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    base_job_name='xgboost-batch-transform',\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9978fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-05 00:10:30 Starting - Starting the training job...\n",
      "2022-01-05 00:10:53 Starting - Launching requested ML instancesProfilerReport-1641341429: InProgress\n",
      "...\n",
      "2022-01-05 00:11:26 Starting - Preparing the instances for training............\n",
      "2022-01-05 00:13:20 Downloading - Downloading input data...\n",
      "2022-01-05 00:13:55 Training - Training image download completed. Training in progress.\n",
      "2022-01-05 00:13:55 Uploading - Uploading generated training model\u001b[34m[2022-01-05 00:13:51.631 ip-10-0-114-219.ap-northeast-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:51:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=7510 sha256=b197179127d03f10e12c66f6ea4a98279899fbc15d9bc038da42c9d8abcff32b\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-dvpdfayb/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:53:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-01-05:00:13:53:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_depth\": \"5\",\n",
      "        \"objective\": \"reg:squarederror\",\n",
      "        \"eta\": \"0.2\",\n",
      "        \"num_round\": \"500\",\n",
      "        \"subsample\": \"0.7\",\n",
      "        \"gamma\": \"4\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"verbosity\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgboost-batch-transform-2022-01-05-00-10-29-871\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2022-01-05-00-10-29-871/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"500\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2022-01-05-00-10-29-871/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"500\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgboost-batch-transform-2022-01-05-00-10-29-871\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2022-01-05-00-10-29-871/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"500\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\",\"--verbosity\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=reg:squarederror\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=500\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_VERBOSITY=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 500 --objective reg:squarederror --subsample 0.7 --verbosity 2\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:19.24118#011validation-rmse:19.95601\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:15.75215#011validation-rmse:16.38510\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:12.91363#011validation-rmse:13.52608\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:10.66743#011validation-rmse:11.28941\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:8.78830#011validation-rmse:9.52816\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:7.33972#011validation-rmse:8.18952\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:6.14948#011validation-rmse:7.03950\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:5.27264#011validation-rmse:6.26622\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:4.52930#011validation-rmse:5.66625\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:3.95899#011validation-rmse:5.27399\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:3.49374#011validation-rmse:4.97541\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:3.13209#011validation-rmse:4.75218\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:2.83112#011validation-rmse:4.58555\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:2.62437#011validation-rmse:4.48671\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:2.46680#011validation-rmse:4.42469\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:2.36915#011validation-rmse:4.38059\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:2.26623#011validation-rmse:4.34073\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:2.18759#011validation-rmse:4.34964\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:2.10211#011validation-rmse:4.34712\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:2.05931#011validation-rmse:4.32084\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:2.01141#011validation-rmse:4.35449\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:1.97301#011validation-rmse:4.31907\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:1.91663#011validation-rmse:4.28586\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:1.87038#011validation-rmse:4.30955\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:1.82032#011validation-rmse:4.28163\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:1.80504#011validation-rmse:4.28857\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:1.76987#011validation-rmse:4.28809\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:1.73823#011validation-rmse:4.25169\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:1.71606#011validation-rmse:4.23968\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:1.67330#011validation-rmse:4.24842\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:1.62559#011validation-rmse:4.26586\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:1.59760#011validation-rmse:4.26000\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:1.55152#011validation-rmse:4.26473\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:1.50853#011validation-rmse:4.27072\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:1.48552#011validation-rmse:4.25470\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:1.46635#011validation-rmse:4.27687\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:1.44115#011validation-rmse:4.28142\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:1.38991#011validation-rmse:4.27546\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:1.36646#011validation-rmse:4.26779\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:1.35044#011validation-rmse:4.24015\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:1.33978#011validation-rmse:4.23646\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:1.31414#011validation-rmse:4.20633\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:1.29130#011validation-rmse:4.21417\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:1.27091#011validation-rmse:4.21721\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:1.24985#011validation-rmse:4.21544\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:1.23660#011validation-rmse:4.19613\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:1.22349#011validation-rmse:4.18851\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:1.19807#011validation-rmse:4.17394\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:1.18812#011validation-rmse:4.17702\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:1.17141#011validation-rmse:4.17989\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:1.15652#011validation-rmse:4.19870\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:1.13550#011validation-rmse:4.19223\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:1.12363#011validation-rmse:4.20107\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:1.11300#011validation-rmse:4.20329\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:1.10449#011validation-rmse:4.21082\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:1.09181#011validation-rmse:4.21811\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:1.06666#011validation-rmse:4.21898\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 4 extra nodes, 20 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:1.06525#011validation-rmse:4.22320\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:1.04762#011validation-rmse:4.18983\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:1.04244#011validation-rmse:4.18913\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:1.04076#011validation-rmse:4.17856\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:1.02975#011validation-rmse:4.15790\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:1.02307#011validation-rmse:4.17094\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:1.01656#011validation-rmse:4.19076\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:1.00606#011validation-rmse:4.19195\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.99547#011validation-rmse:4.18538\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.98517#011validation-rmse:4.18613\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.97999#011validation-rmse:4.18590\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.97276#011validation-rmse:4.18527\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.96251#011validation-rmse:4.18064\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.95313#011validation-rmse:4.19239\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 24 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.94996#011validation-rmse:4.18740\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.94329#011validation-rmse:4.18906\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.93778#011validation-rmse:4.18639\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.93375#011validation-rmse:4.18236\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.92501#011validation-rmse:4.18866\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:0.92514#011validation-rmse:4.18766\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:0.91727#011validation-rmse:4.18391\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:0.91137#011validation-rmse:4.19003\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:0.90431#011validation-rmse:4.18557\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:0.89655#011validation-rmse:4.18624\u001b[0m\n",
      "\u001b[34m[00:13:54] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:0.89306#011validation-rmse:4.19691\u001b[0m\n",
      "\u001b[34mRMSE: 4.196913\u001b[0m\n",
      "\n",
      "2022-01-05 00:14:14 Completed - Training job completed\n",
      "Training seconds: 44\n",
      "Billable seconds: 12\n",
      "Managed Spot Training savings: 72.7%\n"
     ]
    }
   ],
   "source": [
    "xgb_script_mode_estimator_managed.fit(\n",
    "    {'train': input_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa335212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2021-12-11-14-35-53-183/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2021-12-11-14-35-53-183/model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675f148",
   "metadata": {},
   "source": [
    "## Batch transform using SM processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c72a24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2022-01-05-00-10-29-871/output/model.tar.gz'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_artifacts = xgb_script_mode_estimator_managed.model_data\n",
    "model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f93568fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/data'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd4d7fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/preprocessing.py\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "# 로그 생성\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# 로그의 출력 기준 설정\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# log 출력 형식\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# log 출력\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'xgboost'])\n",
    "\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import xgboost as xgb\n",
    "\n",
    "if __name__=='__main__':\n",
    "    logger.info('Starting preprocessing...')\n",
    "    \n",
    "    input_file = '/opt/ml/processing/input/boston.csv'\n",
    "    input = pd.read_csv(input_file)\n",
    "    \n",
    "    logger.info('Input data')\n",
    "    logger.info(input.head())\n",
    "    \n",
    "    logger.info('Loading trained XGBoost model...')\n",
    "    \n",
    "    model_artifacts = '/opt/ml/processing/model/model.tar.gz'\n",
    "    with tarfile.open(model_artifacts) as model:\n",
    "        model.extractall('/opt/ml/processing/model')\n",
    "    \n",
    "    loaded_model = xgb.Booster()\n",
    "    loaded_model.load_model('/opt/ml/processing/model/model.json')\n",
    "    \n",
    "    logger.info('Starting batch prefiction...')\n",
    "    predictions = loaded_model.inplace_predict(input.loc[:, input.columns != 'PRICE'])\n",
    "    input['PREDICTED'] = predictions\n",
    "    \n",
    "    input.to_csv('/opt/ml/processing/results/results.csv', index=False)\n",
    "    logger.info('Output data')\n",
    "    logger.info(input.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9b2c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.23-1',\n",
    "                                     role=role,\n",
    "#                                      instance_type='ml.m5.xlarge',\n",
    "                                     instance_type='local',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99055dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  xgboost-batch-05-00-14-43\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2022-01-05-00-10-29-871/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-05-00-14-43/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'results', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/batch-output/results', 'LocalPath': '/opt/ml/processing/results', 'S3UploadMode': 'EndOfJob'}}]\n",
      "Creating ij9afpw6yu-algo-1-4ye8p ... \n",
      "Creating ij9afpw6yu-algo-1-4ye8p ... done\n",
      "Attaching to ij9afpw6yu-algo-1-4ye8p\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m Collecting xgboost\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m   Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
      "     |████████████████████████████████| 173.5 MB 46.9 MB/s            \n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m \u001b[?25hRequirement already satisfied: scipy in /miniconda3/lib/python3.7/site-packages (from xgboost) (1.5.3)\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m Requirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from xgboost) (1.19.2)\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m Installing collected packages: xgboost\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m Successfully installed xgboost-1.5.1\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,690 - root - INFO - Starting preprocessing...\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,693 - root - INFO - Input data\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,693 - root - INFO -       CRIM  ...  PRICE\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 0  0.00632  ...   24.0\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 1  0.02731  ...   21.6\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2  0.02729  ...   34.7\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 3  0.03237  ...   33.4\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 4  0.06905  ...   36.2\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m \n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m [5 rows x 14 columns]\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,709 - root - INFO - Loading trained XGBoost model...\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,720 - root - INFO - Starting batch prefiction...\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,733 - root - INFO - Output data\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2022-01-05 00:15:42,733 - root - INFO -       CRIM  ...  PREDICTED\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 0  0.00632  ...  24.579475\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 1  0.02731  ...  20.933998\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 2  0.02729  ...  34.499367\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 3  0.03237  ...  33.706867\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m 4  0.06905  ...  35.687893\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m \n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p |\u001b[0m [5 rows x 15 columns]\n",
      "\u001b[36mij9afpw6yu-algo-1-4ye8p exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from time import gmtime, strftime \n",
    "\n",
    "processing_job_name = \"xgboost-batch-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "output_destination = 's3://{}/{}/batch-output'.format(bucket, prefix)\n",
    "\n",
    "inputs = [ProcessingInput(source=input_data,\n",
    "                          destination='/opt/ml/processing/input',\n",
    "                          s3_data_distribution_type='FullyReplicated'),\n",
    "          ProcessingInput(source=model_artifacts,\n",
    "                          destination='/opt/ml/processing/model',\n",
    "                          s3_data_distribution_type='FullyReplicated')]\n",
    "\n",
    "outputs = [ProcessingOutput(output_name='results',\n",
    "                            source='/opt/ml/processing/results',\n",
    "                            destination='{}/results'.format(output_destination))]\n",
    "\n",
    "sklearn_processor.run(code='./source_dir/preprocessing.py',\n",
    "                      job_name=processing_job_name,\n",
    "                      inputs=inputs,\n",
    "                      outputs=outputs)\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62340d",
   "metadata": {},
   "source": [
    "### Download preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac0fff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "968ebe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync {output_destination} ./results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "314958fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56\n",
      "drwxrwxr-x 2 ec2-user ec2-user  4096 Dec 14 07:02 .\n",
      "drwxrwxr-x 3 ec2-user ec2-user  4096 Dec 14 07:02 ..\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 48529 Dec 14 06:57 results.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lat ./results/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9de01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
