{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "188ec5e3",
   "metadata": {},
   "source": [
    "# XGBoost 로컬 학습 후 Batch Transform w/ SM Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7d8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 173.5 MB 59.9 MB/s eta 0:00:01   |█████                           | 27.3 MB 1.6 MB/s eta 0:01:29\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d9f71ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import time\n",
    "from time import gmtime, strftime "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c228ba1",
   "metadata": {},
   "source": [
    "## Prepare & Uplad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18f511e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3a88fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names\n",
    "data['PRICE'] = boston.target\n",
    "\n",
    "data.to_csv('./data/boston.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3ddad471",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'batch-transform/xgboost-byos'\n",
    "output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "569ae127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/data'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = session.upload_data('./data', key_prefix=f'{prefix}/data')\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cc4ee0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:30:25      41085 batch-transform/xgboost-byos/data/.ipynb_checkpoints/boston-checkpoint.csv\n",
      "2021-12-11 14:30:25      39170 batch-transform/xgboost-byos/data/boston.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {input_data} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7c375a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/train.py\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Hyperparameters are described here.\n",
    "parser.add_argument(\"--max_depth\", type=int, default=5)\n",
    "parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "parser.add_argument(\"--gamma\", type=int, default=4)\n",
    "parser.add_argument(\"--min_child_weight\", type=int, default=6)\n",
    "parser.add_argument(\"--subsample\", type=float, default=0.7)\n",
    "parser.add_argument(\"--verbosity\", type=int, default=2)\n",
    "parser.add_argument(\"--objective\", type=str, default='reg:squarederror')\n",
    "parser.add_argument(\"--num_round\", type=int, default=50)\n",
    "parser.add_argument(\"--tree_method\", type=str, default=\"auto\")\n",
    "parser.add_argument(\"--predictor\", type=str, default=\"auto\")\n",
    "\n",
    "# SageMaker specific arguments. Defaults are set in the environment variables.\n",
    "parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "# parser.add_argument('--validation', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "data = pd.read_csv(f'{args.train}/boston.csv')\n",
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "train_hp = {\n",
    "    \"max_depth\": args.max_depth,\n",
    "    \"eta\": args.eta,\n",
    "    \"gamma\": args.gamma,\n",
    "    \"min_child_weight\": args.min_child_weight,\n",
    "    \"subsample\": args.subsample,\n",
    "    \"verbosity\": args.verbosity,\n",
    "    \"objective\": args.objective,\n",
    "    \"tree_method\": args.tree_method,\n",
    "    \"predictor\": args.predictor,\n",
    "}\n",
    "\n",
    "model_xgb = xgb.train(params=train_hp, \n",
    "                      dtrain=train,\n",
    "                      evals=[(train, \"train\"), (test, \"validation\")], \n",
    "                      num_boost_round=100,\n",
    "                      early_stopping_rounds=20)\n",
    "\n",
    "preds = model_xgb.predict(test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "model_xgb.save_model(f'{args.model_dir}/model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67207254",
   "metadata": {},
   "source": [
    "## Local mode training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8ce39f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32dd0fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-regression-2021-12-11-14-35-52\n",
      "Checkpoint path: None\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "use_spot_instances = False\n",
    "job_name = \"DEMO-xgboost-regression-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "checkpoint_s3_uri = (\n",
    "    \"s3://{}/{}/checkpoints/{}\".format(bucket, prefix, job_name) if use_spot_instances else None\n",
    ")\n",
    "print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "\n",
    "xgb_script_mode_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir='source_dir',\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.3-1\",\n",
    "    output_path=output_path,\n",
    "#     use_spot_instances=use_spot_instances,\n",
    "#     max_run=max_run,\n",
    "#     max_wait=max_wait,\n",
    "    base_job_name='xgboost-batch-transform',\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3bdff4de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating r63pd0f5ud-algo-1-wqc6v ... \n",
      "Creating r63pd0f5ud-algo-1-wqc6v ... done\n",
      "Attaching to r63pd0f5ud-algo-1-wqc6v\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11 14:35:56.319 22b88be7b30a:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] Invoking user training script.\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] Module train does not provide a setup.py. \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Generating setup.py\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] Generating setup.cfg\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] Generating MANIFEST.in\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:56:INFO] Installing module with the following command:\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m    pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=4689 sha256=9ea60d6792b93a9e3102ced56b785f82e130da2ca6943ab31da3e366985cc9fe\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-hv3rabxh/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Successfully built train\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Installing collected packages: train\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m You should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:57:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2021-12-11:14:35:57:INFO] Invoking user script\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Training Env:\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m {\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     },\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"current_host\": \"algo-1-wqc6v\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"algo-1-wqc6v\"\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     ],\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"max_depth\": \"5\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"eta\": \"0.2\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"gamma\": \"4\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"min_child_weight\": \"6\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"subsample\": \"0.7\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"objective\": \"reg:squarederror\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"num_round\": \"50\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"verbosity\": \"2\"\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     },\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"train\": {\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         }\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     },\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"job_name\": \"xgboost-batch-transform-2021-12-11-14-35-53-183\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"master_hostname\": \"algo-1-wqc6v\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2021-12-11-14-35-53-183/source/sourcedir.tar.gz\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"current_host\": \"algo-1-wqc6v\",\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m             \"algo-1-wqc6v\"\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m         ]\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     },\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m }\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Environment variables:\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HOSTS=[\"algo-1-wqc6v\"]\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"}\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-wqc6v\",\"hosts\":[\"algo-1-wqc6v\"]}\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_CURRENT_HOST=algo-1-wqc6v\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2021-12-11-14-35-53-183/source/sourcedir.tar.gz\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-wqc6v\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-wqc6v\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:squarederror\",\"subsample\":\"0.7\",\"verbosity\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgboost-batch-transform-2021-12-11-14-35-53-183\",\"log_level\":20,\"master_hostname\":\"algo-1-wqc6v\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-transform-2021-12-11-14-35-53-183/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-wqc6v\",\"hosts\":[\"algo-1-wqc6v\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\",\"--verbosity\",\"2\"]\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_MAX_DEPTH=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_ETA=0.2\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_GAMMA=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_MIN_CHILD_WEIGHT=6\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_SUBSAMPLE=0.7\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_OBJECTIVE=reg:squarederror\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_NUM_ROUND=50\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m SM_HP_VERBOSITY=2\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m /miniconda3/bin/python3 -m train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:squarederror --subsample 0.7 --verbosity 2\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m \n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [0]\ttrain-rmse:19.24118\tvalidation-rmse:19.95601\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [1]\ttrain-rmse:15.75215\tvalidation-rmse:16.38510\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [2]\ttrain-rmse:12.91363\tvalidation-rmse:13.52608\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [3]\ttrain-rmse:10.66743\tvalidation-rmse:11.28941\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [4]\ttrain-rmse:8.78830\tvalidation-rmse:9.52816\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [5]\ttrain-rmse:7.33972\tvalidation-rmse:8.18952\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [6]\ttrain-rmse:6.14948\tvalidation-rmse:7.03950\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [7]\ttrain-rmse:5.27264\tvalidation-rmse:6.26622\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [8]\ttrain-rmse:4.52930\tvalidation-rmse:5.66625\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [9]\ttrain-rmse:3.95899\tvalidation-rmse:5.27399\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [10]\ttrain-rmse:3.49374\tvalidation-rmse:4.97541\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [11]\ttrain-rmse:3.13209\tvalidation-rmse:4.75218\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [12]\ttrain-rmse:2.83112\tvalidation-rmse:4.58555\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [13]\ttrain-rmse:2.62437\tvalidation-rmse:4.48671\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14]\ttrain-rmse:2.46680\tvalidation-rmse:4.42469\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [15]\ttrain-rmse:2.36915\tvalidation-rmse:4.38059\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [16]\ttrain-rmse:2.26623\tvalidation-rmse:4.34073\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [17]\ttrain-rmse:2.18759\tvalidation-rmse:4.34964\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [18]\ttrain-rmse:2.10211\tvalidation-rmse:4.34712\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [19]\ttrain-rmse:2.05931\tvalidation-rmse:4.32084\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [20]\ttrain-rmse:2.01141\tvalidation-rmse:4.35449\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [21]\ttrain-rmse:1.97301\tvalidation-rmse:4.31907\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [22]\ttrain-rmse:1.91663\tvalidation-rmse:4.28586\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [23]\ttrain-rmse:1.87038\tvalidation-rmse:4.30955\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [24]\ttrain-rmse:1.82032\tvalidation-rmse:4.28163\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [25]\ttrain-rmse:1.80504\tvalidation-rmse:4.28857\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [26]\ttrain-rmse:1.76987\tvalidation-rmse:4.28809\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [27]\ttrain-rmse:1.73823\tvalidation-rmse:4.25169\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [28]\ttrain-rmse:1.71606\tvalidation-rmse:4.23968\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [29]\ttrain-rmse:1.67330\tvalidation-rmse:4.24842\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [30]\ttrain-rmse:1.62559\tvalidation-rmse:4.26586\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [31]\ttrain-rmse:1.59760\tvalidation-rmse:4.26000\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [32]\ttrain-rmse:1.55152\tvalidation-rmse:4.26473\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [33]\ttrain-rmse:1.50853\tvalidation-rmse:4.27072\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [34]\ttrain-rmse:1.48552\tvalidation-rmse:4.25470\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [35]\ttrain-rmse:1.46635\tvalidation-rmse:4.27687\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [36]\ttrain-rmse:1.44115\tvalidation-rmse:4.28142\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [37]\ttrain-rmse:1.38991\tvalidation-rmse:4.27546\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [38]\ttrain-rmse:1.36646\tvalidation-rmse:4.26779\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [39]\ttrain-rmse:1.35044\tvalidation-rmse:4.24015\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [40]\ttrain-rmse:1.33978\tvalidation-rmse:4.23646\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [41]\ttrain-rmse:1.31414\tvalidation-rmse:4.20633\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 14 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [42]\ttrain-rmse:1.29130\tvalidation-rmse:4.21417\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [43]\ttrain-rmse:1.27091\tvalidation-rmse:4.21721\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 22 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [44]\ttrain-rmse:1.24985\tvalidation-rmse:4.21544\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [45]\ttrain-rmse:1.23660\tvalidation-rmse:4.19613\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [46]\ttrain-rmse:1.22349\tvalidation-rmse:4.18851\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 22 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [47]\ttrain-rmse:1.19807\tvalidation-rmse:4.17394\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [48]\ttrain-rmse:1.18812\tvalidation-rmse:4.17702\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [49]\ttrain-rmse:1.17141\tvalidation-rmse:4.17989\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [50]\ttrain-rmse:1.15652\tvalidation-rmse:4.19870\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [51]\ttrain-rmse:1.13550\tvalidation-rmse:4.19223\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [52]\ttrain-rmse:1.12363\tvalidation-rmse:4.20107\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [53]\ttrain-rmse:1.11300\tvalidation-rmse:4.20330\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 10 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [54]\ttrain-rmse:1.10449\tvalidation-rmse:4.21082\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [55]\ttrain-rmse:1.09181\tvalidation-rmse:4.21811\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [56]\ttrain-rmse:1.06666\tvalidation-rmse:4.21898\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 4 extra nodes, 20 pruned nodes, max_depth=2\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [57]\ttrain-rmse:1.06525\tvalidation-rmse:4.22320\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [58]\ttrain-rmse:1.04762\tvalidation-rmse:4.18983\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 6 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [59]\ttrain-rmse:1.04244\tvalidation-rmse:4.18913\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 16 pruned nodes, max_depth=3\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [60]\ttrain-rmse:1.04076\tvalidation-rmse:4.17856\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [61]\ttrain-rmse:1.02975\tvalidation-rmse:4.15790\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [62]\ttrain-rmse:1.02307\tvalidation-rmse:4.17094\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [63]\ttrain-rmse:1.01656\tvalidation-rmse:4.19076\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 16 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [64]\ttrain-rmse:1.00606\tvalidation-rmse:4.19195\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [65]\ttrain-rmse:0.99547\tvalidation-rmse:4.18538\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 14 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [66]\ttrain-rmse:0.98517\tvalidation-rmse:4.18613\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 20 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [67]\ttrain-rmse:0.97999\tvalidation-rmse:4.18590\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 16 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [68]\ttrain-rmse:0.97276\tvalidation-rmse:4.18527\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [69]\ttrain-rmse:0.96251\tvalidation-rmse:4.18064\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 6 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [70]\ttrain-rmse:0.95313\tvalidation-rmse:4.19239\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 24 pruned nodes, max_depth=3\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [71]\ttrain-rmse:0.94996\tvalidation-rmse:4.18740\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 8 extra nodes, 10 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [72]\ttrain-rmse:0.94329\tvalidation-rmse:4.18906\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [73]\ttrain-rmse:0.93778\tvalidation-rmse:4.18639\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [74]\ttrain-rmse:0.93375\tvalidation-rmse:4.18236\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 14 extra nodes, 18 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [75]\ttrain-rmse:0.92501\tvalidation-rmse:4.18866\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [76]\ttrain-rmse:0.92514\tvalidation-rmse:4.18766\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 12 extra nodes, 8 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [77]\ttrain-rmse:0.91727\tvalidation-rmse:4.18391\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 2 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [78]\ttrain-rmse:0.91137\tvalidation-rmse:4.19003\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [79]\ttrain-rmse:0.90431\tvalidation-rmse:4.18557\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 10 extra nodes, 20 pruned nodes, max_depth=4\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [80]\ttrain-rmse:0.89655\tvalidation-rmse:4.18624\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m [14:35:58] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 6 extra nodes, 14 pruned nodes, max_depth=3\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v |\u001b[0m RMSE: 4.196913\n",
      "\u001b[36mr63pd0f5ud-algo-1-wqc6v exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "xgb_script_mode_estimator.fit(\n",
    "    {'train': input_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "15c9f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2021-12-11-14-35-53-183/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2021-12-11-14-35-53-183/model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc6e32",
   "metadata": {},
   "source": [
    "### #TODO Local deploy\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_inferenece_script_mode.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "# model_data = xgb_script_mode_estimator.model_data\n",
    "# print(model_data)\n",
    "\n",
    "# xgb_inference_model = XGBoostModel(\n",
    "#     model_data=model_data,\n",
    "#     role=role,\n",
    "#     entry_point=\"inference.py\",\n",
    "#     source_dir='source_dir',\n",
    "#     framework_version=\"1.3-1\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9818af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = xgb_inference_model.deploy(\n",
    "#     initial_instance_count=1,\n",
    "# #     instance_type=\"ml.c5.xlarge\",\n",
    "#     instance_type='local'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aef2ff",
   "metadata": {},
   "source": [
    "## Processing for Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "63966481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/output/xgboost-batch-transform-2021-12-11-14-35-53-183/model.tar.gz'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_artifacts = xgb_script_mode_estimator.model_data\n",
    "model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "774941e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/data'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0a7b38f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source_dir/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source_dir/preprocessing.py\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'xgboost'])\n",
    "\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import xgboost as xgb\n",
    "\n",
    "if __name__=='__main__':\n",
    "    input_file = '/opt/ml/processing/input/boston.csv'\n",
    "    input = pd.read_csv(input_file)\n",
    "    \n",
    "    model_artifacts = '/opt/ml/processing/model/model.tar.gz'\n",
    "    with tarfile.open(model_artifacts) as model:\n",
    "        model.extractall('/opt/ml/processing/model')\n",
    "    \n",
    "    loaded_model = xgb.Booster()\n",
    "    loaded_model.load_model('/opt/ml/processing/model/model.json')\n",
    "    \n",
    "    predictions = loaded_model.inplace_predict(input.loc[:, input.columns != 'PRICE'])\n",
    "    input['PREDICTED'] = predictions\n",
    "    \n",
    "    input.to_csv('/opt/ml/processing/results/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "61f609be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.23-1',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "#                                      instance_type='local',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "786f5c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  xgboost-batch-11-16-06-21\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-11-16-06-21/input/input-2/model.tar.gz', 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/xgboost-batch-11-16-06-21/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'results', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-889750940888/batch-transform/xgboost-byos/batch-output/results', 'LocalPath': '/opt/ml/processing/results', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".........................\u001b[34mCollecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.7/site-packages (from xgboost) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from xgboost) (1.19.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xgboost\u001b[0m\n",
      "\u001b[34mSuccessfully installed xgboost-1.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from time import gmtime, strftime \n",
    "\n",
    "processing_job_name = \"xgboost-batch-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "output_destination = 's3://{}/{}/batch-output'.format(bucket, prefix)\n",
    "\n",
    "inputs = [ProcessingInput(source=input_data,\n",
    "                          destination='/opt/ml/processing/input',\n",
    "                          s3_data_distribution_type='FullyReplicated'),\n",
    "          ProcessingInput(source=model_artifacts,\n",
    "                          destination='/opt/ml/processing/model',\n",
    "                          s3_data_distribution_type='FullyReplicated')]\n",
    "\n",
    "outputs = [ProcessingOutput(output_name='results',\n",
    "                            source='/opt/ml/processing/results',\n",
    "                            destination='{}/results'.format(output_destination))]\n",
    "\n",
    "sklearn_processor.run(code='./source_dir/preprocessing.py',\n",
    "                      job_name=processing_job_name,\n",
    "                      inputs=inputs,\n",
    "                      outputs=outputs)\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbd9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ca419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796991c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29800074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
