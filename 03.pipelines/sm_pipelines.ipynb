{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb01656c",
   "metadata": {},
   "source": [
    "# SageMaker Pipelines Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4dd28",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05dce10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f0265",
   "metadata": {},
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b143ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() \n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), 'data/train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "test_dir = os.path.join(os.getcwd(), 'data/test')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "raw_dir = os.path.join(os.getcwd(), 'data/raw')\n",
    "os.makedirs(raw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb994cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-889750940888/sm-pipelines/data/raw\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.datasets import boston_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "np.save(os.path.join(raw_dir, 'x_train.npy'), x_train)\n",
    "np.save(os.path.join(raw_dir, 'x_test.npy'), x_test)\n",
    "np.save(os.path.join(train_dir, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(test_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "s3_prefix = 'sm-pipelines'\n",
    "rawdata_s3_prefix = '{}/data/raw'.format(s3_prefix)\n",
    "raw_s3 = sess.upload_data(path='./data/raw/', key_prefix=rawdata_s3_prefix)\n",
    "print(raw_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b1794",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d394c",
   "metadata": {},
   "source": [
    "### Pipelines 변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b565d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat\n",
    ")\n",
    "\n",
    "### ProcessingStep\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "processing_input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=raw_s3,\n",
    ")\n",
    "\n",
    "### TrainingStep\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value= 1\n",
    ")\n",
    "\n",
    "# training_hp_epochs = ParameterInteger(\n",
    "training_hp_epochs = ParameterString(\n",
    "    name=\"TrainingHPEpochs\",\n",
    "    default_value= '5'\n",
    ")\n",
    "\n",
    "# training_hp_batch_size = ParameterInteger(\n",
    "training_hp_batch_size = ParameterString(\n",
    "    name=\"TrainingHPBatchSize\",\n",
    "    default_value= '128'\n",
    ")\n",
    "\n",
    "# training_hp_learning_rate = ParameterFloat(\n",
    "training_hp_learning_rate = ParameterString(\n",
    "    name=\"TrainingHPLearningRate\",\n",
    "    default_value= '0.01'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31543a7f",
   "metadata": {},
   "source": [
    "### Caching config\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "426b410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_config = sagemaker.workflow.steps.CacheConfig(enable_caching=True, expire_after=\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac8d06f",
   "metadata": {},
   "source": [
    "## ProcessingStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41850c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e89babbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data: \n",
      " s3://sagemaker-us-east-1-889750940888/sm-pipelines/data/raw\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sm-pipelines\",\n",
    "    role=role,\n",
    ")\n",
    "print(\"input_data: \\n\", processing_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "715f4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "output_destination = 's3://{}/{}/data'.format(bucket, s3_prefix)\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Processing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=raw_s3,\n",
    "                        destination='/opt/ml/processing/input',\n",
    "                        s3_data_distribution_type='ShardedByS3Key')\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"train\",\n",
    "                              source='/opt/ml/processing/train',\n",
    "                              destination='{}/train'.format(output_destination)),\n",
    "             ProcessingOutput(output_name=\"test\",\n",
    "                              source='/opt/ml/processing/test',\n",
    "                              destination='{}/test'.format(output_destination))\n",
    "    ],\n",
    "#     job_arguments=[\"--split_rate\", f\"{split_rate}\"],    \n",
    "    code= 'preprocessing.py',\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dc7899b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/train/y_train.npy to s3://sagemaker-us-east-1-889750940888/sm-pipelines/data/train/y_train.npy\n",
      "upload: data/test/y_test.npy to s3://sagemaker-us-east-1-889750940888/sm-pipelines/data/test/y_test.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {train_dir}/y_train.npy {output_destination}/train/y_train.npy\n",
    "!aws s3 cp {test_dir}/y_test.npy {output_destination}/test/y_test.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a58e41af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-07 02:28:05      10736 sm-pipelines/data/raw/x_test.npy\n",
      "2021-12-07 02:28:05      42144 sm-pipelines/data/raw/x_train.npy\n",
      "2021-12-07 08:49:13      10736 sm-pipelines/data/test/x_test.npy\n",
      "2021-12-07 08:56:41        944 sm-pipelines/data/test/y_test.npy\n",
      "2021-12-07 08:49:13      42144 sm-pipelines/data/train/x_train.npy\n",
      "2021-12-07 08:56:40       3360 sm-pipelines/data/train/y_train.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {output_destination} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77a4fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_process.properties.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968d8d2",
   "metadata": {},
   "source": [
    "## TrainingStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "39fd4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "hyperparameters = {'epochs': training_hp_epochs,\n",
    "                   'batch_size': training_hp_batch_size,\n",
    "                   'learning_rate': training_hp_learning_rate}\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': ' loss: ([0-9\\\\.]+)'},\n",
    "                     {'Name': 'val_loss',\n",
    "                       'Regex': ' val_loss: ([0-9\\\\.]+)'}]\n",
    "\n",
    "estimator = TensorFlow(source_dir='train_model',\n",
    "                       entry_point='train.py',\n",
    "#                       model_dir=model_dir,\n",
    "                       instance_type=training_instance_type,\n",
    "                       instance_count=training_instance_count,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       role=role,\n",
    "                       base_job_name='sm-pipelines',\n",
    "                       framework_version='2.1',\n",
    "                       py_version='py3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b039f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"Training\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data= step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data= step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96211606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88a5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "115c124c",
   "metadata": {},
   "source": [
    "## Pipelines 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a39be05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = 'sm-pipelines-demo'\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type, \n",
    "        processing_instance_count,\n",
    "        processing_input_data,\n",
    "        training_instance_type,\n",
    "        training_instance_count,\n",
    "        training_hp_epochs,\n",
    "        training_hp_batch_size,\n",
    "        training_hp_learning_rate\n",
    "    ],\n",
    "    steps=[step_process, step_train],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e773f5",
   "metadata": {},
   "source": [
    "**파이프라인을 SageMaker에 제출하고 실행하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e4822eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:889750940888:pipeline/sm-pipelines-demo',\n",
       " 'ResponseMetadata': {'RequestId': 'f25ae144-2ee0-412d-a09d-d19211a4bc3e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f25ae144-2ee0-412d-a09d-d19211a4bc3e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '85',\n",
       "   'date': 'Tue, 07 Dec 2021 09:02:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26d538d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ProcessingInstanceCount=2,\n",
    "        TrainingHPEpochs=100\n",
    "    )    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f0eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02461d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ed1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
